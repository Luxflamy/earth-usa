{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting arrival delay prediction models (Random Forest)...\n",
      "Flight data directory: ./cleaned_data/\n",
      "Weather data directory: ./cleaned_weather_data/\n",
      "Top airports file: ./top_100_airports.csv\n",
      "Model output directory: ./rf_arrival_delay_models/\n",
      "Loaded top 30 airports: ATL, AUS, BNA, BOS, BWI, CLT, DCA, DEN, DFW, DTW, EWR, FLL, IAD, IAH, JFK, LAS, LAX, LGA, MCO, MDW, MIA, MSP, ORD, PHL, PHX, SAN, SEA, SFO, SLC, TPA\n",
      "Busiest airport: ATL with 457121 flights\n",
      "30th busiest airport: TPA with 97235 flights\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from joblib import dump\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 添加转换函数用于JSON序列化\n",
    "def convert_to_serializable(obj):\n",
    "    \"\"\"\n",
    "    Convert NumPy types to Python native types for JSON serialization\n",
    "    \"\"\"\n",
    "    if isinstance(obj, (np.integer, np.int64, np.int32, np.int16, np.int8)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating, np.float64, np.float32, np.float16)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.ndarray,)):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (pd.DataFrame,)):\n",
    "        return obj.to_dict('records')\n",
    "    elif isinstance(obj, (pd.Series,)):\n",
    "        return obj.to_dict()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(item) for item in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# Set data paths\n",
    "flight_data_path = './cleaned_data/'\n",
    "weather_data_path = './cleaned_weather_data/'\n",
    "top_airports_file = './top_100_airports.csv'  # File containing top 100 airports\n",
    "output_dir = './rf_arrival_delay_models/'  # 更改为降落延迟模型的输出目录\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"Starting arrival delay prediction models (Random Forest)...\")\n",
    "print(f\"Flight data directory: {flight_data_path}\")\n",
    "print(f\"Weather data directory: {weather_data_path}\")\n",
    "print(f\"Top airports file: {top_airports_file}\")\n",
    "print(f\"Model output directory: {output_dir}\")\n",
    "\n",
    "# Load top 30 airports from the top 100 airports file\n",
    "try:\n",
    "    # Load the airport data with the exact format provided\n",
    "    top_airports = pd.read_csv(top_airports_file, low_memory=False)\n",
    "    \n",
    "    # The file already has a Rank column, so we can just take the top 30\n",
    "    top_airports = top_airports.head(30)\n",
    "    \n",
    "    # The airport codes are in ORIGIN_IATA column\n",
    "    top_airport_codes = set(top_airports['ORIGIN_IATA'].str.strip().tolist())\n",
    "    \n",
    "    print(f\"Loaded top 30 airports: {', '.join(sorted(top_airport_codes))}\")\n",
    "    print(f\"Busiest airport: {top_airports.iloc[0]['ORIGIN_IATA']} with {top_airports.iloc[0]['Times']} flights\")\n",
    "    print(f\"30th busiest airport: {top_airports.iloc[29]['ORIGIN_IATA']} with {top_airports.iloc[29]['Times']} flights\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading top airports file: {e}\")\n",
    "    # Fallback: if file doesn't exist, we'll use all airports\n",
    "    top_airport_codes = None\n",
    "    print(\"Will process all airports (top airports file not available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 4 May files to process:\n",
      "  - May2021.csv\n",
      "  - May2022.csv\n",
      "  - May2023.csv\n",
      "  - May2024.csv\n",
      "\n",
      "Loading weather data...\n",
      "Found 3550 total weather data files\n",
      "Processed 100 weather files, loaded 0 matching files\n",
      "Processed 200 weather files, loaded 0 matching files\n",
      "Processed 300 weather files, loaded 16 matching files\n",
      "Processed 400 weather files, loaded 32 matching files\n",
      "Processed 500 weather files, loaded 32 matching files\n",
      "Processed 600 weather files, loaded 48 matching files\n",
      "Processed 700 weather files, loaded 48 matching files\n",
      "Processed 800 weather files, loaded 48 matching files\n",
      "Processed 900 weather files, loaded 64 matching files\n",
      "Processed 1000 weather files, loaded 64 matching files\n",
      "Processed 1100 weather files, loaded 80 matching files\n",
      "Processed 1200 weather files, loaded 96 matching files\n",
      "Processed 1300 weather files, loaded 112 matching files\n",
      "Processed 1400 weather files, loaded 112 matching files\n",
      "Processed 1500 weather files, loaded 112 matching files\n",
      "Processed 1600 weather files, loaded 112 matching files\n",
      "Processed 1700 weather files, loaded 128 matching files\n",
      "Processed 1800 weather files, loaded 128 matching files\n",
      "Processed 1900 weather files, loaded 143 matching files\n",
      "Processed 2000 weather files, loaded 160 matching files\n",
      "Processed 2100 weather files, loaded 160 matching files\n",
      "Processed 2200 weather files, loaded 192 matching files\n",
      "Processed 2300 weather files, loaded 208 matching files\n",
      "Processed 2400 weather files, loaded 208 matching files\n",
      "Processed 2500 weather files, loaded 224 matching files\n",
      "Processed 2600 weather files, loaded 240 matching files\n",
      "Processed 2700 weather files, loaded 240 matching files\n",
      "Processed 2800 weather files, loaded 256 matching files\n",
      "Processed 2900 weather files, loaded 256 matching files\n",
      "Processed 3000 weather files, loaded 272 matching files\n",
      "Processed 3100 weather files, loaded 286 matching files\n",
      "Processed 3200 weather files, loaded 306 matching files\n",
      "Processed 3300 weather files, loaded 320 matching files\n",
      "Processed 3400 weather files, loaded 336 matching files\n",
      "Processed 3500 weather files, loaded 336 matching files\n",
      "Loaded 336 weather files out of 3550 processed files\n",
      "Loading weather data took: 0.62 seconds\n"
     ]
    }
   ],
   "source": [
    "# Function to load weather data - adjusted for the new format ABI_2021_Aug.csv\n",
    "def load_weather_data():\n",
    "    print(\"\\nLoading weather data...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    all_files = glob.glob(os.path.join(weather_data_path, \"*.csv\"))\n",
    "    print(f\"Found {len(all_files)} total weather data files\")\n",
    "    weather_dict = {}\n",
    "    count = 0\n",
    "    matching_count = 0\n",
    "    \n",
    "    # Process all weather files\n",
    "    for file in all_files:\n",
    "        try:\n",
    "            # Extract airport code and date information from filename\n",
    "            filename = os.path.basename(file)\n",
    "            parts = filename.split('.')[0].split('_')\n",
    "            \n",
    "            if len(parts) >= 3:\n",
    "                iata = parts[0]  # Airport code (e.g., ABI)\n",
    "                year = parts[1]  # Year (e.g., 2021)\n",
    "                month_name = parts[2]  # Month name (e.g., Aug)\n",
    "                \n",
    "                # Convert month name to number\n",
    "                month_map = {\n",
    "                    'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04',\n",
    "                    'May': '05', 'Jun': '06', 'Jul': '07', 'Aug': '08',\n",
    "                    'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'\n",
    "                }\n",
    "                \n",
    "                if month_name in month_map:\n",
    "                    month = month_map[month_name]\n",
    "                    \n",
    "                    # Only continue with top airports if we have a list\n",
    "                    if top_airport_codes is None or iata in top_airport_codes:\n",
    "                        # Read the weather data\n",
    "                        weather_data = pd.read_csv(file, low_memory=False)\n",
    "                        \n",
    "                        # Ensure DATE column exists\n",
    "                        if 'DATE' not in weather_data.columns:\n",
    "                            print(f\"Warning: DATE column not found in {filename}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # Convert DATE to datetime\n",
    "                        weather_data['DATE'] = pd.to_datetime(weather_data['DATE'])\n",
    "                        \n",
    "                        # Create the key for the weather dictionary\n",
    "                        key = f\"{iata}_{year}_{month}\"\n",
    "                        \n",
    "                        # Store the weather data\n",
    "                        weather_dict[key] = weather_data\n",
    "                        matching_count += 1\n",
    "                else:\n",
    "                    print(f\"Warning: Unknown month format in {filename}\")\n",
    "                \n",
    "                count += 1\n",
    "                \n",
    "                # Print progress periodically\n",
    "                if count % 100 == 0:\n",
    "                    print(f\"Processed {count} weather files, loaded {matching_count} matching files\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading weather file {file}: {e}\")\n",
    "    \n",
    "    print(f\"Loaded {matching_count} weather files out of {count} processed files\")\n",
    "    print(f\"Loading weather data took: {time.time() - start_time:.2f} seconds\")\n",
    "    return weather_dict\n",
    "\n",
    "# Get specific May files from the cleaned_data directory\n",
    "def get_may_files():\n",
    "    may_files = [\n",
    "        os.path.join(flight_data_path, \"May2021.csv\"),\n",
    "        os.path.join(flight_data_path, \"May2022.csv\"),\n",
    "        os.path.join(flight_data_path, \"May2023.csv\"),\n",
    "        os.path.join(flight_data_path, \"May2024.csv\")\n",
    "    ]\n",
    "    \n",
    "    # Verify each file exists\n",
    "    existing_files = []\n",
    "    for file_path in may_files:\n",
    "        if os.path.exists(file_path):\n",
    "            existing_files.append(file_path)\n",
    "        else:\n",
    "            print(f\"Warning: File {file_path} not found\")\n",
    "    \n",
    "    return existing_files\n",
    "\n",
    "# Get the May 2021-2024 flight data files\n",
    "flight_files = get_may_files()\n",
    "print(f\"\\nFound {len(flight_files)} May files to process:\")\n",
    "for f in flight_files:\n",
    "    print(f\"  - {os.path.basename(f)}\")\n",
    "\n",
    "if not flight_files:\n",
    "    print(\"No May 2021-2024 files were found. Please check file paths.\")\n",
    "    exit(1)\n",
    "\n",
    "# Load all weather data once\n",
    "weather_dict = load_weather_data()\n",
    "\n",
    "# Function to extract year from filename\n",
    "def extract_year_from_filename(filename):\n",
    "    # Extract year from 'May2021.csv', 'May2022.csv', etc.\n",
    "    base_name = os.path.basename(filename)\n",
    "    year_str = base_name.replace('May', '').split('.')[0]\n",
    "    return int(year_str)\n",
    "\n",
    "# Function to create late-night arrival indicator\n",
    "def create_late_night_arrival_indicator(df):\n",
    "    \"\"\"\n",
    "    Creates a binary indicator for late-night arrivals (22-06 scheduled arrival time)\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing flight data with SCH_ARR_TIME\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with IS_LATE_NIGHT_ARR column added\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Initialize IS_LATE_NIGHT_ARR to 0 (not a late-night arrival)\n",
    "    df['IS_LATE_NIGHT_ARR'] = 0\n",
    "    \n",
    "    # Check for SCH_ARR_TIME\n",
    "    if 'SCH_ARR_TIME' not in df.columns:\n",
    "        print(\"Warning: SCH_ARR_TIME column not found\")\n",
    "        return df\n",
    "    \n",
    "    # Convert time column to standard format if needed\n",
    "    if df['SCH_ARR_TIME'].dtype != 'float64':\n",
    "        try:\n",
    "            # Handle any non-numeric values\n",
    "            df['SCH_ARR_TIME'] = pd.to_numeric(df['SCH_ARR_TIME'], errors='coerce')\n",
    "        except:\n",
    "            print(f\"Warning: Could not convert SCH_ARR_TIME to numeric\")\n",
    "    \n",
    "    # Identify late-night arrivals (22:00-06:00)\n",
    "    late_night_arrival = ((df['SCH_ARR_TIME'] >= 2200) | (df['SCH_ARR_TIME'] < 600))\n",
    "    df.loc[late_night_arrival, 'IS_LATE_NIGHT_ARR'] = 1\n",
    "    \n",
    "    # Count arrivals identified as late-night\n",
    "    late_night_count = late_night_arrival.sum()\n",
    "    total_count = len(df)\n",
    "    print(f\"Identified {late_night_count} late-night arrivals (22:00-06:00)\")\n",
    "    print(f\"Total identified late-night arrivals: {late_night_count} out of {total_count} total flights ({late_night_count/total_count*100:.2f}%)\")\n",
    "    \n",
    "    # Add a more detailed arrival time-of-day categorical feature\n",
    "    df['ARR_TIME_OF_DAY'] = pd.cut(\n",
    "        df['SCH_ARR_TIME'], \n",
    "        bins=[0, 600, 1200, 1800, 2200, 2400],\n",
    "        labels=['Early Morning (0-6)', 'Morning (6-12)', 'Afternoon (12-18)', 'Evening (18-22)', 'Night (22-24)'],\n",
    "        include_lowest=True\n",
    "    )\n",
    "    \n",
    "    # Print distribution of flights by arrival time of day\n",
    "    time_dist = df['ARR_TIME_OF_DAY'].value_counts()\n",
    "    print(\"\\nDistribution of flights by arrival time of day:\")\n",
    "    for time_cat, count in time_dist.items():\n",
    "        print(f\"  - {time_cat}: {count} flights ({count/total_count*100:.2f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to prepare arrival delay data - focus on ARR_DELAY\n",
    "def prepare_arrival_delay_data(df):\n",
    "    \"\"\"\n",
    "    Prepares arrival delay data for modeling\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing flight data with ARR_DELAY column\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with additional arrival delay-related columns\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure ARR_DELAY is numeric\n",
    "    if 'ARR_DELAY' in df.columns:\n",
    "        if df['ARR_DELAY'].dtype != 'float64':\n",
    "            try:\n",
    "                df['ARR_DELAY'] = pd.to_numeric(df['ARR_DELAY'], errors='coerce')\n",
    "            except:\n",
    "                print(f\"Warning: Could not convert ARR_DELAY to numeric\")\n",
    "    else:\n",
    "        print(\"Warning: ARR_DELAY column not found in dataset\")\n",
    "        return df\n",
    "    \n",
    "    # Create a binary feature for on-time arrival (<=0 means on time or early)\n",
    "    df['IS_ARR_DELAYED'] = (df['ARR_DELAY'] > 0).astype(int)\n",
    "    \n",
    "    # Create a categorical arrival delay feature\n",
    "    df['ARR_DELAY_CATEGORY'] = pd.cut(\n",
    "        df['ARR_DELAY'],\n",
    "        bins=[-float('inf'), -15, 0, 15, 30, 60, 120, float('inf')],\n",
    "        labels=['Very Early', 'Early', 'On Time', 'Slight Delay', 'Moderate Delay', \n",
    "                'Significant Delay', 'Severe Delay'],\n",
    "        include_lowest=True\n",
    "    )\n",
    "    \n",
    "    # Add absolute arrival delay (for prediction error metrics)\n",
    "    df['ABS_ARR_DELAY'] = np.abs(df['ARR_DELAY'])\n",
    "    \n",
    "    # Print arrival delay statistics\n",
    "    delay_count = df['IS_ARR_DELAYED'].sum()\n",
    "    total_count = len(df)\n",
    "    delay_rate = delay_count / total_count * 100\n",
    "    \n",
    "    print(f\"\\nArrival delay statistics:\")\n",
    "    print(f\"Delayed arrivals: {delay_count}/{total_count} ({delay_rate:.2f}%)\")\n",
    "    print(f\"On-time or early arrivals: {total_count - delay_count}/{total_count} ({100 - delay_rate:.2f}%)\")\n",
    "    \n",
    "    print(\"\\nArrival delay magnitude statistics:\")\n",
    "    print(f\"Mean arrival delay: {df['ARR_DELAY'].mean():.2f} minutes\")\n",
    "    print(f\"Median arrival delay: {df['ARR_DELAY'].median():.2f} minutes\")\n",
    "    print(f\"Min arrival delay: {df['ARR_DELAY'].min():.2f} minutes (negative means early arrival)\")\n",
    "    print(f\"Max arrival delay: {df['ARR_DELAY'].max():.2f} minutes\")\n",
    "    \n",
    "    # Print arrival delay category distribution\n",
    "    delay_cat_dist = df['ARR_DELAY_CATEGORY'].value_counts()\n",
    "    print(\"\\nArrival delay category distribution:\")\n",
    "    for cat, count in delay_cat_dist.sort_index().items():\n",
    "        print(f\"  - {cat}: {count} flights ({count/total_count*100:.2f}%)\")\n",
    "    \n",
    "    # Create a feature to indicate if arrival delay is worse than departure delay\n",
    "    if 'DEP_DELAY' in df.columns:\n",
    "        df['ARR_WORSE_THAN_DEP'] = ((df['ARR_DELAY'] - df['DEP_DELAY']) > 0).astype(int)\n",
    "        worse_count = df['ARR_WORSE_THAN_DEP'].sum()\n",
    "        print(f\"\\nFlights with arrival delay worse than departure delay: {worse_count}/{total_count} ({worse_count/total_count*100:.2f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to create arrival time block features\n",
    "def create_arrival_time_block_features(df):\n",
    "    \"\"\"\n",
    "    Creates time block features from scheduled arrival times\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing flight data with SCH_ARR_TIME\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with arrival time block features added\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    if 'SCH_ARR_TIME' not in df.columns:\n",
    "        print(\"Warning: SCH_ARR_TIME column not found for arrival time block features\")\n",
    "        return df\n",
    "    \n",
    "    # Ensure SCH_ARR_TIME is numeric\n",
    "    if df['SCH_ARR_TIME'].dtype != 'float64':\n",
    "        try:\n",
    "            df['SCH_ARR_TIME'] = pd.to_numeric(df['SCH_ARR_TIME'], errors='coerce')\n",
    "        except:\n",
    "            print(f\"Warning: Could not convert SCH_ARR_TIME to numeric\")\n",
    "            return df\n",
    "    \n",
    "    # Extract hour from SCH_ARR_TIME (time format is HHMM)\n",
    "    df['ARR_HOUR'] = (df['SCH_ARR_TIME'] / 100).astype(int)\n",
    "    \n",
    "    # Create time blocks (each block is 3 hours)\n",
    "    time_blocks = {\n",
    "        0: 'Late Night (0-3)',\n",
    "        1: 'Late Night (0-3)',\n",
    "        2: 'Late Night (0-3)',\n",
    "        3: 'Early Morning (3-6)',\n",
    "        4: 'Early Morning (3-6)',\n",
    "        5: 'Early Morning (3-6)',\n",
    "        6: 'Morning (6-9)',\n",
    "        7: 'Morning (6-9)',\n",
    "        8: 'Morning (6-9)',\n",
    "        9: 'Mid-Day (9-12)',\n",
    "        10: 'Mid-Day (9-12)',\n",
    "        11: 'Mid-Day (9-12)',\n",
    "        12: 'Afternoon (12-15)',\n",
    "        13: 'Afternoon (12-15)',\n",
    "        14: 'Afternoon (12-15)',\n",
    "        15: 'Evening (15-18)',\n",
    "        16: 'Evening (15-18)',\n",
    "        17: 'Evening (15-18)',\n",
    "        18: 'Night (18-21)',\n",
    "        19: 'Night (18-21)',\n",
    "        20: 'Night (18-21)',\n",
    "        21: 'Late Night (21-24)',\n",
    "        22: 'Late Night (21-24)',\n",
    "        23: 'Late Night (21-24)'\n",
    "    }\n",
    "    \n",
    "    # Map hours to time blocks\n",
    "    df['ARR_TIME_BLOCK'] = df['ARR_HOUR'].map(time_blocks)\n",
    "    \n",
    "    # Create binary variables for peak arrival times\n",
    "    # Morning rush (8-10 AM arrivals)\n",
    "    df['IS_MORNING_RUSH_ARR'] = ((df['ARR_HOUR'] >= 8) & (df['ARR_HOUR'] <= 10)).astype(int)\n",
    "    \n",
    "    # Evening rush (17-19 PM arrivals)\n",
    "    df['IS_EVENING_RUSH_ARR'] = ((df['ARR_HOUR'] >= 17) & (df['ARR_HOUR'] <= 19)).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to create day of week features - updated for text day format (Sun, Mon, etc.)\n",
    "def create_day_features(df):\n",
    "    \"\"\"\n",
    "    Creates day type features from text day names (Sun, Mon, etc.)\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing flight data with WEEK column as text day names\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with day features added\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Check if we have the WEEK column with text day names\n",
    "    if 'WEEK' in df.columns:\n",
    "        # Create a mapping from abbreviated day names to full day names\n",
    "        day_name_map = {\n",
    "            'Sun': 'Sunday',\n",
    "            'Mon': 'Monday',\n",
    "            'Tue': 'Tuesday',\n",
    "            'Wed': 'Wednesday',\n",
    "            'Thu': 'Thursday',\n",
    "            'Fri': 'Friday',\n",
    "            'Sat': 'Saturday'\n",
    "        }\n",
    "        \n",
    "        # Map abbreviated names to full names\n",
    "        df['DAY_NAME'] = df['WEEK'].map(day_name_map)\n",
    "        \n",
    "        # Create weekend indicator\n",
    "        df['IS_WEEKEND'] = df['WEEK'].isin(['Sat', 'Sun']).astype(int)\n",
    "        \n",
    "        # Print distribution of days\n",
    "        day_counts = df['DAY_NAME'].value_counts()\n",
    "        total = len(df)\n",
    "        print(\"\\nDistribution of flights by day of week:\")\n",
    "        for day, count in day_counts.items():\n",
    "            print(f\"  - {day}: {count} flights ({count/total*100:.2f}%)\")\n",
    "        \n",
    "        # Print weekend vs. weekday distribution\n",
    "        weekend_count = df['IS_WEEKEND'].sum()\n",
    "        weekday_count = total - weekend_count\n",
    "        print(f\"\\nWeekend flights: {weekend_count} ({weekend_count/total*100:.2f}%)\")\n",
    "        print(f\"Weekday flights: {weekday_count} ({weekday_count/total*100:.2f}%)\")\n",
    "        \n",
    "    elif 'DAY_OF_WEEK' in df.columns:\n",
    "        # Assuming 1=Monday, ..., 7=Sunday or 0=Monday, ..., 6=Sunday\n",
    "        max_day = df['DAY_OF_WEEK'].max()\n",
    "        \n",
    "        if max_day == 7:\n",
    "            # 1-7 format (6,7 = weekend)\n",
    "            df['IS_WEEKEND'] = ((df['DAY_OF_WEEK'] == 6) | (df['DAY_OF_WEEK'] == 7)).astype(int)\n",
    "            \n",
    "            # Map day numbers to names for better interpretability\n",
    "            day_names = {1: 'Monday', 2: 'Tuesday', 3: 'Wednesday', \n",
    "                        4: 'Thursday', 5: 'Friday', 6: 'Saturday', 7: 'Sunday'}\n",
    "        else:\n",
    "            # 0-6 format (5,6 = weekend)\n",
    "            df['IS_WEEKEND'] = ((df['DAY_OF_WEEK'] == 5) | (df['DAY_OF_WEEK'] == 6)).astype(int)\n",
    "            \n",
    "            # Map day numbers to names for better interpretability\n",
    "            day_names = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', \n",
    "                        3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'}\n",
    "        \n",
    "        df['DAY_NAME'] = df['DAY_OF_WEEK'].map(day_names)\n",
    "    else:\n",
    "        print(\"Warning: No day of week column (WEEK or DAY_OF_WEEK) found\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to create flight duration features\n",
    "def create_flight_duration_features(df):\n",
    "    \"\"\"\n",
    "    Creates features related to flight duration and arrival time\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing flight data\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with flight duration features added\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Calculate scheduled flight duration if possible\n",
    "    if 'SCH_ARR_TIME' in df.columns and 'SCH_DEP_TIME' in df.columns:\n",
    "        try:\n",
    "            # Convert to numeric if needed\n",
    "            for col in ['SCH_ARR_TIME', 'SCH_DEP_TIME']:\n",
    "                if df[col].dtype != 'float64':\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # Calculate scheduled flight duration (handle overnight flights)\n",
    "            df['SCH_DURATION'] = ((df['SCH_ARR_TIME'] - df['SCH_DEP_TIME']) % 2400)\n",
    "            \n",
    "            # Fix cases where arrival is before departure (overnight flights)\n",
    "            # If we get a negative or very large value, add 2400 (24 hours)\n",
    "            mask = df['SCH_DURATION'] < 0\n",
    "            df.loc[mask, 'SCH_DURATION'] += 2400\n",
    "            \n",
    "            # Convert HHMM format to minutes (e.g., 130 = 1 hour 30 minutes = 90 minutes)\n",
    "            df['SCH_DURATION_MINS'] = (df['SCH_DURATION'] // 100) * 60 + (df['SCH_DURATION'] % 100)\n",
    "            \n",
    "            # Calculate actual flight duration if possible\n",
    "            if 'ACT_ARR_TIME' in df.columns and 'ACT_DEP_TIME' in df.columns:\n",
    "                for col in ['ACT_ARR_TIME', 'ACT_DEP_TIME']:\n",
    "                    if df[col].dtype != 'float64':\n",
    "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "                df['ACT_DURATION'] = ((df['ACT_ARR_TIME'] - df['ACT_DEP_TIME']) % 2400)\n",
    "                mask = df['ACT_DURATION'] < 0\n",
    "                df.loc[mask, 'ACT_DURATION'] += 2400\n",
    "                \n",
    "                df['ACT_DURATION_MINS'] = (df['ACT_DURATION'] // 100) * 60 + (df['ACT_DURATION'] % 100)\n",
    "                \n",
    "                # Calculate duration difference (negative means flight was faster than scheduled)\n",
    "                df['DURATION_DIFF'] = df['ACT_DURATION_MINS'] - df['SCH_DURATION_MINS']\n",
    "                \n",
    "                # Print statistics\n",
    "                print(\"\\nFlight duration statistics:\")\n",
    "                print(f\"Mean scheduled duration: {df['SCH_DURATION_MINS'].mean():.1f} minutes\")\n",
    "                print(f\"Mean actual duration: {df['ACT_DURATION_MINS'].mean():.1f} minutes\")\n",
    "                print(f\"Mean duration difference: {df['DURATION_DIFF'].mean():.1f} minutes\")\n",
    "                print(f\"Flights faster than scheduled: {(df['DURATION_DIFF'] < 0).sum()} ({(df['DURATION_DIFF'] < 0).mean()*100:.1f}%)\")\n",
    "                print(f\"Flights slower than scheduled: {(df['DURATION_DIFF'] > 0).sum()} ({(df['DURATION_DIFF'] > 0).mean()*100:.1f}%)\")\n",
    "                \n",
    "                # Create duration deviation categories\n",
    "                df['DURATION_DEVIATION'] = pd.cut(\n",
    "                    df['DURATION_DIFF'],\n",
    "                    bins=[-float('inf'), -15, -5, 5, 15, 30, float('inf')],\n",
    "                    labels=['Much Faster', 'Faster', 'On Schedule', 'Slower', 'Much Slower', 'Extremely Slower']\n",
    "                )\n",
    "                \n",
    "                # Print duration deviation distribution\n",
    "                dev_dist = df['DURATION_DEVIATION'].value_counts()\n",
    "                print(\"\\nFlight duration deviation distribution:\")\n",
    "                for dev, count in dev_dist.sort_index().items():\n",
    "                    print(f\"  - {dev}: {count} flights ({count/len(df)*100:.2f}%)\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating flight durations: {e}\")\n",
    "    \n",
    "    # Create flight distance categories if DISTANCE is available\n",
    "    if 'DISTANCE' in df.columns:\n",
    "        df['FLIGHT_DISTANCE_CAT'] = pd.cut(\n",
    "            df['DISTANCE'],\n",
    "            bins=[0, 300, 600, 1000, 1500, float('inf')],\n",
    "            labels=['Very Short (<300 mi)', 'Short (300-600 mi)', 'Medium (600-1000 mi)', \n",
    "                   'Long (1000-1500 mi)', 'Very Long (>1500 mi)']\n",
    "        )\n",
    "        \n",
    "        # Print flight distance distribution\n",
    "        dist_dist = df['FLIGHT_DISTANCE_CAT'].value_counts()\n",
    "        print(\"\\nFlight distance distribution:\")\n",
    "        for dist, count in dist_dist.sort_index().items():\n",
    "            print(f\"  - {dist}: {count} flights ({count/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to match weather data to flights for origin airports (departure weather)\n",
    "def match_weather_data(df):\n",
    "    \"\"\"\n",
    "    Match weather data to flight records for origin airports\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing flight data\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with origin weather data added\n",
    "    \"\"\"\n",
    "    print(\"\\nMatching origin weather data with flights...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Make sure necessary date columns exist\n",
    "    date_columns_exist = all(col in df.columns for col in ['YEAR', 'MONTH', 'DAY'])\n",
    "    if not date_columns_exist:\n",
    "        print(\"Warning: Missing one or more date columns (YEAR, MONTH, DAY)\")\n",
    "        print(\"Weather data cannot be matched\")\n",
    "        return df\n",
    "    \n",
    "    # Create a date column for matching - convert to datetime\n",
    "    df['FLIGHT_DATE'] = pd.to_datetime(df[['YEAR', 'MONTH', 'DAY']])\n",
    "    \n",
    "    # Create a column to hold the weather key pattern\n",
    "    df['WEATHER_KEY'] = df['ORIGIN_IATA'] + '_' + df['YEAR'].astype(str) + '_' + df['MONTH'].astype(str).str.zfill(2)\n",
    "    \n",
    "    # Create columns for weather features\n",
    "    weather_columns = ['EXTREME_WEATHER', 'PRCP', 'WT01', 'WT03', 'WT04', 'WT05', 'WT08', 'WT11']\n",
    "    for col in weather_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0.0\n",
    "    \n",
    "    # Process in batches\n",
    "    matched_count = 0\n",
    "    batch_size = 10000\n",
    "    \n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        batch = df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        for idx, row in batch.iterrows():\n",
    "            try:\n",
    "                # Get the weather key based on the origin airport and date\n",
    "                weather_key = row['WEATHER_KEY']\n",
    "                flight_date = row['FLIGHT_DATE']\n",
    "                \n",
    "                # Check if this key exists in our weather dictionary\n",
    "                if weather_key in weather_dict:\n",
    "                    weather_data = weather_dict[weather_key]\n",
    "                    \n",
    "                    # Find matching weather data for the flight date\n",
    "                    matching_weather = weather_data[weather_data['DATE'] == flight_date]\n",
    "                    \n",
    "                    if not matching_weather.empty:\n",
    "                        # Match available weather columns for origin\n",
    "                        for col in weather_columns:\n",
    "                            if col in matching_weather.columns:\n",
    "                                df.at[idx, col] = matching_weather[col].iloc[0]\n",
    "                        matched_count += 1\n",
    "            except Exception as e:\n",
    "                # Less verbose error reporting for speed\n",
    "                pass\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Processed {end_idx}/{len(df)} rows, matched {matched_count} flights with origin weather data\")\n",
    "    \n",
    "    print(f\"Matched origin weather data for {matched_count} flights ({matched_count/len(df)*100:.2f}%)\")\n",
    "    print(f\"Origin weather matching took: {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to match weather data to flights for destination airports (for arrival delays)\n",
    "def match_destination_weather_data(df):\n",
    "    \"\"\"\n",
    "    Match weather data to flight destination records for arrival delay analysis\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing flight data\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with destination weather data added\n",
    "    \"\"\"\n",
    "    print(\"\\nMatching destination weather data with flights...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Make sure necessary date columns exist\n",
    "    date_columns_exist = all(col in df.columns for col in ['YEAR', 'MONTH', 'DAY'])\n",
    "    if not date_columns_exist:\n",
    "        print(\"Warning: Missing one or more date columns (YEAR, MONTH, DAY)\")\n",
    "        print(\"Weather data cannot be matched\")\n",
    "        return df\n",
    "    \n",
    "    # Create a date column for matching - convert to datetime\n",
    "    if 'FLIGHT_DATE' not in df.columns:\n",
    "        df['FLIGHT_DATE'] = pd.to_datetime(df[['YEAR', 'MONTH', 'DAY']])\n",
    "    \n",
    "    # Create a column to hold the destination weather key pattern\n",
    "    df['DEST_WEATHER_KEY'] = df['DEST_IATA'] + '_' + df['YEAR'].astype(str) + '_' + df['MONTH'].astype(str).str.zfill(2)\n",
    "    \n",
    "    # Create columns for weather features\n",
    "    weather_columns = ['EXTREME_WEATHER', 'PRCP', 'WT01', 'WT03', 'WT04', 'WT05', 'WT08', 'WT11']\n",
    "    for col in weather_columns:\n",
    "        if f'DEST_{col}' not in df.columns:\n",
    "            df[f'DEST_{col}'] = 0.0\n",
    "    \n",
    "    # Process in batches\n",
    "    matched_count = 0\n",
    "    batch_size = 10000\n",
    "    \n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        batch = df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        for idx, row in batch.iterrows():\n",
    "            try:\n",
    "                # Get the weather key based on the destination airport and date\n",
    "                weather_key = row['DEST_WEATHER_KEY']\n",
    "                flight_date = row['FLIGHT_DATE']\n",
    "                \n",
    "                # Check if this key exists in our weather dictionary\n",
    "                if weather_key in weather_dict:\n",
    "                    weather_data = weather_dict[weather_key]\n",
    "                    \n",
    "                    # Find matching weather data for the flight date\n",
    "                    matching_weather = weather_data[weather_data['DATE'] == flight_date]\n",
    "                    \n",
    "                    if not matching_weather.empty:\n",
    "                        # Match available weather columns for destination\n",
    "                        for col in weather_columns:\n",
    "                            if col in matching_weather.columns:\n",
    "                                df.at[idx, f'DEST_{col}'] = matching_weather[col].iloc[0]\n",
    "                        matched_count += 1\n",
    "            except Exception as e:\n",
    "                # Less verbose error reporting for speed\n",
    "                pass\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Processed {end_idx}/{len(df)} rows, matched {matched_count} flights with destination weather data\")\n",
    "    \n",
    "    print(f\"Matched destination weather data for {matched_count} flights ({matched_count/len(df)*100:.2f}%)\")\n",
    "    print(f\"Destination weather matching took: {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to load and preprocess a single flight data file\n",
    "def load_and_process_flight_data(file_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess a single flight data file\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the flight data file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with processed flight data\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing {os.path.basename(file_path)}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Load flight data\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "        original_size = len(df)\n",
    "        \n",
    "        # Extract year from filename\n",
    "        file_year = extract_year_from_filename(file_path)\n",
    "        \n",
    "        # Ensure the year is properly set\n",
    "        if 'YEAR' in df.columns:\n",
    "            # Verify that the year in the data matches the filename\n",
    "            unique_years = df['YEAR'].unique()\n",
    "            print(f\"Years found in data: {unique_years}\")\n",
    "            \n",
    "            # If data has multiple years, filter to only the year from filename\n",
    "            if len(unique_years) > 1:\n",
    "                df = df[df['YEAR'] == file_year]\n",
    "                print(f\"Filtered to only year {file_year}: {len(df)} rows\")\n",
    "        else:\n",
    "            # If no YEAR column exists, create one based on filename\n",
    "            df['YEAR'] = file_year\n",
    "            print(f\"Added YEAR column with value {file_year}\")\n",
    "        \n",
    "        # Ensure we only have May data\n",
    "        if 'MONTH' in df.columns:\n",
    "            month_counts = df['MONTH'].value_counts()\n",
    "            print(f\"Months found in data: {dict(month_counts)}\")\n",
    "            \n",
    "            if 5 in month_counts:\n",
    "                df = df[df['MONTH'] == 5]\n",
    "                print(f\"Filtered to only May data: {len(df)} rows\")\n",
    "            else:\n",
    "                print(f\"Warning: No May data found in file, but proceeding anyway as this should be May data based on filename\")\n",
    "        \n",
    "        # Check for ARR_DELAY column (required for arrival delay prediction)\n",
    "        if 'ARR_DELAY' not in df.columns:\n",
    "            print(f\"ARR_DELAY column not found in {os.path.basename(file_path)}. Skipping file.\")\n",
    "            return None\n",
    "        \n",
    "        # Filter for top airports if we have the list\n",
    "        if top_airport_codes is not None:\n",
    "            df = df[\n",
    "                df['ORIGIN_IATA'].str.strip().isin(top_airport_codes) & \n",
    "                df['DEST_IATA'].str.strip().isin(top_airport_codes)\n",
    "            ]\n",
    "            \n",
    "            filtered_size = len(df)\n",
    "            print(f\"Filtered from {original_size} to {filtered_size} rows for top 30 airports\")\n",
    "            \n",
    "            # If no data left after filtering, skip this file\n",
    "            if filtered_size == 0:\n",
    "                print(f\"No data remaining after filtering for top 30 airports. Skipping file.\")\n",
    "                return None\n",
    "        \n",
    "        # Remove cancelled flights since they don't have actual arrival times\n",
    "        if 'CANCELLED' in df.columns:\n",
    "            cancelled_count = df['CANCELLED'].sum()\n",
    "            if cancelled_count > 0:\n",
    "                df = df[df['CANCELLED'] == 0]\n",
    "                print(f\"Removed {cancelled_count} cancelled flights, remaining: {len(df)}\")\n",
    "        \n",
    "        # Remove diverted flights since they have special handling\n",
    "        if 'DIVERTED' in df.columns:\n",
    "            diverted_count = df['DIVERTED'].sum()\n",
    "            if diverted_count > 0:\n",
    "                df = df[df['DIVERTED'] == 0]\n",
    "                print(f\"Removed {diverted_count} diverted flights, remaining: {len(df)}\")\n",
    "        \n",
    "        # Verify we have the required arrival time columns\n",
    "        required_columns = ['SCH_ARR_TIME', 'ARR_DELAY']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            print(f\"Missing required arrival time columns: {missing_columns}. Skipping file.\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"Processing took: {time.time() - start_time:.2f} seconds\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {os.path.basename(file_path)}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to plot feature importances (for random forest)\n",
    "def plot_feature_importance(model, feature_names, year, top_n=15, output_path=None, model_type='classification'):\n",
    "    \"\"\"\n",
    "    Visualize the feature importances of a random forest model\n",
    "    \n",
    "    Args:\n",
    "        model: Trained random forest model\n",
    "        feature_names: Names of the features\n",
    "        year: Year of the model (for title)\n",
    "        top_n: Number of top features to show\n",
    "        output_path: Path to save the plot\n",
    "        model_type: 'classification' or 'regression'\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with feature importance data\n",
    "    \"\"\"\n",
    "    # Extract feature importances\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    # Create DataFrame with features and importances\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    })\n",
    "    \n",
    "    # Sort by importance\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Take top N features\n",
    "    top_features = importance_df.head(top_n)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=top_features)\n",
    "    \n",
    "    plt.title(f'Top {top_n} Most Important Features for Arrival Delay (Random Forest {model_type.title()} - {year})')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if output_path:\n",
    "        plt.savefig(output_path)\n",
    "        print(f\"Feature importance plot saved to {output_path}\")\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Function to analyze the correlation between departure and arrival delays\n",
    "def analyze_delay_correlation(df, year, output_dir):\n",
    "    \"\"\"\n",
    "    Analyze the correlation between departure and arrival delays\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing flight data with DEP_DELAY and ARR_DELAY\n",
    "        year: Year of the data\n",
    "        output_dir: Directory to save output plots\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with correlation statistics\n",
    "    \"\"\"\n",
    "    print(\"\\nAnalyzing correlation between departure and arrival delays...\")\n",
    "    \n",
    "    if 'DEP_DELAY' not in df.columns or 'ARR_DELAY' not in df.columns:\n",
    "        print(\"Cannot analyze correlation: missing DEP_DELAY or ARR_DELAY columns\")\n",
    "        return {}\n",
    "    \n",
    "    # Calculate correlation\n",
    "    delay_corr = df[['DEP_DELAY', 'ARR_DELAY']].corr().iloc[0, 1]\n",
    "    print(f\"Correlation between departure and arrival delays: {delay_corr:.4f}\")\n",
    "    \n",
    "    # Calculate difference statistics\n",
    "    df['DELAY_DIFF'] = df['ARR_DELAY'] - df['DEP_DELAY']\n",
    "    mean_diff = df['DELAY_DIFF'].mean()\n",
    "    median_diff = df['DELAY_DIFF'].median()\n",
    "    \n",
    "    print(f\"Mean difference (ARR_DELAY - DEP_DELAY): {mean_diff:.2f} minutes\")\n",
    "    print(f\"Median difference: {median_diff:.2f} minutes\")\n",
    "    print(f\"Flights where arrival delay > departure delay: {(df['DELAY_DIFF'] > 0).sum()} ({(df['DELAY_DIFF'] > 0).mean()*100:.1f}%)\")\n",
    "    print(f\"Flights where arrival delay < departure delay: {(df['DELAY_DIFF'] < 0).sum()} ({(df['DELAY_DIFF'] < 0).mean()*100:.1f}%)\")\n",
    "    \n",
    "    # Create plots\n",
    "    # 1. Scatter plot of departure vs arrival delay\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Sample if there are too many points\n",
    "    max_points = 5000\n",
    "    if len(df) > max_points:\n",
    "        sample_df = df.sample(max_points, random_state=42)\n",
    "    else:\n",
    "        sample_df = df\n",
    "    \n",
    "    plt.scatter(sample_df['DEP_DELAY'], sample_df['ARR_DELAY'], alpha=0.3)\n",
    "    \n",
    "    # Add perfect correlation line (y=x)\n",
    "    max_delay = max(sample_df['DEP_DELAY'].max(), sample_df['ARR_DELAY'].max())\n",
    "    min_delay = min(sample_df['DEP_DELAY'].min(), sample_df['ARR_DELAY'].min())\n",
    "    plt.plot([min_delay, max_delay], [min_delay, max_delay], 'r--', label='Perfect Correlation')\n",
    "    \n",
    "    # Add a regression line\n",
    "    # Calculate regression coefficients\n",
    "    from scipy import stats\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(sample_df['DEP_DELAY'], sample_df['ARR_DELAY'])\n",
    "    plt.plot([min_delay, max_delay], [intercept + slope * min_delay, intercept + slope * max_delay], \n",
    "             'g-', label=f'Regression Line (y = {slope:.2f}x + {intercept:.2f})')\n",
    "    \n",
    "    plt.xlabel('Departure Delay (minutes)')\n",
    "    plt.ylabel('Arrival Delay (minutes)')\n",
    "    plt.title(f'Departure vs. Arrival Delay ({year}, r = {delay_corr:.4f})')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(os.path.join(output_dir, f'dep_vs_arr_delay_scatter_{year}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Histogram of delay differences\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Limit the range for better visualization\n",
    "    df_filtered = df[(df['DELAY_DIFF'] >= -60) & (df['DELAY_DIFF'] <= 60)]\n",
    "    sns.histplot(df_filtered['DELAY_DIFF'], bins=50, kde=True)\n",
    "    \n",
    "    plt.axvline(0, color='red', linestyle='--', label='No Difference')\n",
    "    plt.axvline(mean_diff, color='green', linestyle='-', label=f'Mean Difference: {mean_diff:.2f} min')\n",
    "    plt.axvline(median_diff, color='blue', linestyle='-', label=f'Median Difference: {median_diff:.2f} min')\n",
    "    \n",
    "    plt.xlabel('Arrival Delay - Departure Delay (minutes)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of Delay Differences ({year})')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(os.path.join(output_dir, f'delay_difference_histogram_{year}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Heatmap of departure vs arrival delay\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Create delay categories for both departure and arrival\n",
    "    dep_cats = pd.cut(df['DEP_DELAY'], \n",
    "                    bins=[-100, -15, 0, 15, 30, 60, 120, 1000],\n",
    "                    labels=['Early (>15m)', 'Early (0-15m)', 'Delayed (0-15m)', 'Delayed (15-30m)', \n",
    "                           'Delayed (30-60m)', 'Delayed (60-120m)', 'Delayed (>120m)'])\n",
    "    \n",
    "    arr_cats = pd.cut(df['ARR_DELAY'], \n",
    "                    bins=[-100, -15, 0, 15, 30, 60, 120, 1000],\n",
    "                    labels=['Early (>15m)', 'Early (0-15m)', 'Delayed (0-15m)', 'Delayed (15-30m)', \n",
    "                           'Delayed (30-60m)', 'Delayed (60-120m)', 'Delayed (>120m)'])\n",
    "    \n",
    "    # Create cross-tabulation\n",
    "    delay_cross = pd.crosstab(arr_cats, dep_cats, normalize=True) * 100\n",
    "    \n",
    "    # Plot heatmap\n",
    "    ax = sns.heatmap(delay_cross, annot=True, fmt='.1f', cmap='YlGnBu', linewidths=.5)\n",
    "    \n",
    "    plt.xlabel('Departure Delay Category')\n",
    "    plt.ylabel('Arrival Delay Category')\n",
    "    plt.title(f'Relationship Between Departure and Arrival Delay Categories ({year})')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(os.path.join(output_dir, f'delay_category_heatmap_{year}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    return {\n",
    "        'delay_correlation': delay_corr,\n",
    "        'mean_delay_diff': mean_diff,\n",
    "        'median_delay_diff': median_diff,\n",
    "        'pct_arr_worse_than_dep': (df['DELAY_DIFF'] > 0).mean() * 100,\n",
    "        'pct_arr_better_than_dep': (df['DELAY_DIFF'] < 0).mean() * 100\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to train model for a specific year\n",
    "def train_year_model(year, flight_data_file):\n",
    "    \"\"\"\n",
    "    Train an arrival delay model for a specific year's data\n",
    "    \n",
    "    Args:\n",
    "        year: Year to train model for\n",
    "        flight_data_file: Path to the flight data file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with model results or None if error\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Training Arrival Delay model for year {year}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Create year-specific output directories\n",
    "    year_output_dir = os.path.join(output_dir, f'year_{year}')\n",
    "    os.makedirs(year_output_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(year_output_dir, 'metrics'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(year_output_dir, 'plots'), exist_ok=True)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Step 1: Load and preprocess the year's flight data\n",
    "    flight_data = load_and_process_flight_data(flight_data_file)\n",
    "    if flight_data is None or len(flight_data) == 0:\n",
    "        print(f\"No valid flight data available for {year}. Skipping this year.\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Match departure weather data (origin airport)\n",
    "    flight_data = match_weather_data(flight_data)\n",
    "    \n",
    "    # Step 3: Match arrival weather data (destination airport)\n",
    "    flight_data = match_destination_weather_data(flight_data)\n",
    "    \n",
    "    # Step 4: Analyze correlation between departure and arrival delays\n",
    "    corr_stats = analyze_delay_correlation(flight_data, year, os.path.join(year_output_dir, 'plots'))\n",
    "    \n",
    "    # Step 5: Add feature enhancements specific to arrival delays\n",
    "    # Add late-night arrival indicator\n",
    "    print(f\"\\nCreating late-night arrival indicator for {year}...\")\n",
    "    flight_data = create_late_night_arrival_indicator(flight_data)\n",
    "    \n",
    "    # Prepare arrival delay data\n",
    "    print(f\"\\nPreparing arrival delay data for {year}...\")\n",
    "    flight_data = prepare_arrival_delay_data(flight_data)\n",
    "    \n",
    "    # Create arrival time block features\n",
    "    print(f\"\\nCreating arrival time block features for {year}...\")\n",
    "    flight_data = create_arrival_time_block_features(flight_data)\n",
    "    \n",
    "    # Create day features\n",
    "    print(f\"\\nCreating day features for {year}...\")\n",
    "    flight_data = create_day_features(flight_data)\n",
    "    \n",
    "    # Create flight duration features\n",
    "    print(f\"\\nCreating flight duration features for {year}...\")\n",
    "    flight_data = create_flight_duration_features(flight_data)\n",
    "    \n",
    "    # Step 6: Feature selection for arrival delay prediction\n",
    "    print(f\"\\nSelecting features for arrival delay prediction for {year}...\")\n",
    "    \n",
    "    # Categorical features for arrival delay\n",
    "    cat_features = ['DAY_NAME', 'ARR_TIME_BLOCK', 'MKT_AIRLINE', \n",
    "                    'ORIGIN_IATA', 'DEST_IATA', 'FLIGHT_DISTANCE_CAT', 'DURATION_DEVIATION',\n",
    "                    'IS_LATE_NIGHT_ARR', 'IS_WEEKEND', 'IS_MORNING_RUSH_ARR', 'IS_EVENING_RUSH_ARR',\n",
    "                    \"EXTREME_WEATHER\", 'DEST_EXTREME_WEATHER']\n",
    "    \n",
    "    # Numerical features for arrival delay - include both departure and arrival info\n",
    "    num_features = [\n",
    "        # Basic flight info\n",
    "        'DISTANCE', 'SCH_DURATION_MINS', \n",
    "        \n",
    "        # Weather at origin\n",
    "        'PRCP', \n",
    "        \n",
    "        # Weather at destination\n",
    "        'DEST_PRCP',\n",
    "        \n",
    "        # Departure delay features (extremely important for arrival delay)\n",
    "        'DEP_DELAY'\n",
    "    ]\n",
    "    \n",
    "    # Ensure all selected features exist in the dataframe\n",
    "    cat_features = [f for f in cat_features if f in flight_data.columns]\n",
    "    num_features = [f for f in num_features if f in flight_data.columns]\n",
    "    \n",
    "    print(f\"Using categorical features: {cat_features}\")\n",
    "    print(f\"Using numerical features: {num_features}\")\n",
    "    \n",
    "    # Step 7: Prepare data for modeling\n",
    "    X = flight_data[cat_features + num_features].copy()\n",
    "    y_class = flight_data['IS_ARR_DELAYED']\n",
    "    y_reg = flight_data['ARR_DELAY']\n",
    "\n",
    "    # 首先处理目标变量中的NaN值\n",
    "    if y_reg.isnull().any():\n",
    "        print(f\"Warning: Found {y_reg.isnull().sum()} NaN values in ARR_DELAY. Removing these records.\")\n",
    "        # 创建有效数据的掩码\n",
    "        valid_mask = ~y_reg.isnull()\n",
    "        # 过滤数据集\n",
    "        X = X[valid_mask]\n",
    "        y_class = y_class[valid_mask]\n",
    "        y_reg = y_reg[valid_mask]\n",
    "        print(f\"After removing NaN values, remaining records: {len(X)}\")\n",
    "\n",
    "    # Handle missing values in features\n",
    "    for col in cat_features:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            # Check if it's a categorical type\n",
    "            if pd.api.types.is_categorical_dtype(X[col]):\n",
    "                # Get current categories and add 'unknown'\n",
    "                current_categories = X[col].cat.categories.tolist()\n",
    "                if 'unknown' not in current_categories:\n",
    "                    new_categories = current_categories + ['unknown']\n",
    "                    X[col] = X[col].cat.set_categories(new_categories)\n",
    "                X[col] = X[col].fillna('unknown')\n",
    "            else:\n",
    "                X[col] = X[col].fillna('unknown')\n",
    "\n",
    "    for col in num_features:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            print(f\"Filling {X[col].isnull().sum()} NaN values in column {col} with median\")\n",
    "            X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "    # Final check for any remaining NaN values\n",
    "    if X.isnull().any().any():\n",
    "        print(\"Warning: There are still NaN values in X features after preprocessing\")\n",
    "        # Optional: print columns with NaN values\n",
    "        for col in X.columns[X.isnull().any()]:\n",
    "            print(f\"  - Column {col} has {X[col].isnull().sum()} NaN values\")\n",
    "\n",
    "    # Split data for classification model\n",
    "    X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
    "        X, y_class, test_size=0.25, random_state=42, stratify=y_class\n",
    "    )\n",
    "\n",
    "    # Split data for regression model (no stratify for regression)\n",
    "    X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "        X, y_reg, test_size=0.25, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Training set size: {X_train_class.shape}\")\n",
    "    print(f\"Test set size: {X_test_class.shape}\")\n",
    "\n",
    "    # Extra verification step to ensure no NaN values exist in the training data\n",
    "    if np.isnan(y_train_reg.values).any():\n",
    "        print(\"Warning: NaN values still present in y_train_reg after splitting!\")\n",
    "        # Replace any remaining NaNs with the median as a last resort\n",
    "        median_value = np.nanmedian(y_train_reg)\n",
    "        y_train_reg = y_train_reg.fillna(median_value)\n",
    "        print(f\"Replaced remaining NaN values with median: {median_value}\")\n",
    "\n",
    "    if np.isnan(y_test_reg.values).any():\n",
    "        print(\"Warning: NaN values still present in y_test_reg after splitting!\")\n",
    "        # Replace any remaining NaNs with the median as a last resort\n",
    "        median_value = np.nanmedian(y_test_reg)\n",
    "        y_test_reg = y_test_reg.fillna(median_value)\n",
    "        print(f\"Replaced remaining NaN values with median: {median_value}\")\n",
    "    \n",
    "    # Step 8: Define preprocessing pipeline\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_features),\n",
    "            ('cat', categorical_transformer, cat_features)\n",
    "        ])\n",
    "    \n",
    "    # Step 9: Train classification model for arrival delay (Random Forest)\n",
    "    print(f\"\\nTraining arrival delay classification model for {year} (Random Forest)...\")\n",
    "    class_model_start_time = time.time()\n",
    "    \n",
    "    # 使用随机森林分类器进行到达延迟分类\n",
    "    class_model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=20,\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=5,\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Train classification model\n",
    "    class_model.fit(X_train_class, y_train_class)\n",
    "    final_class_model = class_model\n",
    "    \n",
    "    class_model_training_time = time.time() - class_model_start_time\n",
    "    print(f\"Arrival delay classification model training took: {class_model_training_time:.2f} seconds\")\n",
    "    \n",
    "    # Step 10: Train regression model for arrival delay (Random Forest)\n",
    "    print(f\"\\nTraining arrival delay regression model for {year} (Random Forest)...\")\n",
    "    reg_model_start_time = time.time()\n",
    "    \n",
    "    # 使用随机森林回归器进行到达延迟时长预测\n",
    "    reg_model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(\n",
    "            n_estimators=200,\n",
    "            max_depth=20,\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=5,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Train regression model\n",
    "    reg_model.fit(X_train_reg, y_train_reg)\n",
    "    final_reg_model = reg_model\n",
    "    \n",
    "    reg_model_training_time = time.time() - reg_model_start_time\n",
    "    print(f\"Arrival delay regression model training took: {reg_model_training_time:.2f} seconds\")\n",
    "    \n",
    "    # Step 11: Evaluate classification model\n",
    "    print(f\"\\nEvaluating arrival delay classification model for {year}...\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_class = final_class_model.predict(X_test_class)\n",
    "    y_prob_class = final_class_model.predict_proba(X_test_class)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    class_accuracy = (y_pred_class == y_test_class).mean() * 100\n",
    "    class_roc_auc = roc_auc_score(y_test_class, y_prob_class)\n",
    "    \n",
    "    # Create classification report\n",
    "    class_report = classification_report(y_test_class, y_pred_class, output_dict=True)\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    class_cm = confusion_matrix(y_test_class, y_pred_class)\n",
    "    \n",
    "    print(f\"Arrival Delay Classification Accuracy: {class_accuracy:.2f}%\")\n",
    "    print(f\"Arrival Delay Classification ROC AUC: {class_roc_auc:.4f}\")\n",
    "    print(f\"Arrival Delay Classification Precision (Delayed): {class_report['1']['precision']:.4f}\")\n",
    "    print(f\"Arrival Delay Classification Recall (Delayed): {class_report['1']['recall']:.4f}\")\n",
    "    print(f\"Arrival Delay Classification F1 Score (Delayed): {class_report['1']['f1-score']:.4f}\")\n",
    "    \n",
    "    # Step 12: Evaluate regression model\n",
    "    print(f\"\\nEvaluating arrival delay regression model for {year}...\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_reg = final_reg_model.predict(X_test_reg)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    reg_mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "    reg_rmse = np.sqrt(reg_mse)\n",
    "    reg_mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "    reg_r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "    \n",
    "    print(f\"Arrival Delay Regression Mean Squared Error: {reg_mse:.2f}\")\n",
    "    print(f\"Arrival Delay Regression Root Mean Squared Error: {reg_rmse:.2f} minutes\")\n",
    "    print(f\"Arrival Delay Regression Mean Absolute Error: {reg_mae:.2f} minutes\")\n",
    "    print(f\"Arrival Delay Regression R² Score: {reg_r2:.4f}\")\n",
    "    \n",
    "    # Step 13: Extract feature importances for both models\n",
    "    try:\n",
    "        # Get feature names from the preprocessor\n",
    "        feature_names = final_class_model.named_steps['preprocessor'].get_feature_names_out()\n",
    "        \n",
    "        # Get the random forest classifier\n",
    "        rf_classifier = final_class_model.named_steps['classifier']\n",
    "        \n",
    "        # Plot and save feature importances for classification\n",
    "        class_importance_df = plot_feature_importance(\n",
    "            rf_classifier, \n",
    "            feature_names,\n",
    "            year=year,\n",
    "            top_n=20,\n",
    "            output_path=os.path.join(year_output_dir, 'plots', f'arrival_delay_class_feature_importance_{year}.png'),\n",
    "            model_type='classification'\n",
    "        )\n",
    "        \n",
    "        # Save feature importances to CSV\n",
    "        class_importance_df.to_csv(\n",
    "            os.path.join(year_output_dir, 'metrics', f\"arrival_delay_class_feature_importance_{year}.csv\"), \n",
    "            index=False\n",
    "        )\n",
    "        \n",
    "        # Print top features\n",
    "        print(f\"\\nTop 10 most important features for arrival delay classification in {year}:\")\n",
    "        print(class_importance_df.head(10))\n",
    "        \n",
    "        # Analyze day of week (DAY_NAME) feature importance\n",
    "        day_features = [f for f in feature_names if 'DAY_NAME' in f]\n",
    "        if day_features:\n",
    "            day_importance = class_importance_df[class_importance_df['Feature'].isin(day_features)]\n",
    "            print(f\"\\nDay of week feature importance for arrival delay classification in {year}:\")\n",
    "            print(day_importance)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting classification feature importances: {e}\")\n",
    "        class_importance_df = pd.DataFrame()\n",
    "    \n",
    "    # Extract feature importances for regression model\n",
    "    try:\n",
    "        # Get the random forest regressor\n",
    "        rf_regressor = final_reg_model.named_steps['regressor']\n",
    "        \n",
    "        # Plot and save feature importances for regression\n",
    "        reg_importance_df = plot_feature_importance(\n",
    "            rf_regressor, \n",
    "            feature_names,\n",
    "            year=year,\n",
    "            top_n=20,\n",
    "            output_path=os.path.join(year_output_dir, 'plots', f'arrival_delay_reg_feature_importance_{year}.png'),\n",
    "            model_type='regression'\n",
    "        )\n",
    "        \n",
    "        # Save feature importances to CSV\n",
    "        reg_importance_df.to_csv(\n",
    "            os.path.join(year_output_dir, 'metrics', f\"arrival_delay_reg_feature_importance_{year}.csv\"), \n",
    "            index=False\n",
    "        )\n",
    "        \n",
    "        # Print top features\n",
    "        print(f\"\\nTop 10 most important features for arrival delay regression in {year}:\")\n",
    "        print(reg_importance_df.head(10))\n",
    "        \n",
    "        # Analyze day of week feature importance\n",
    "        if day_features:\n",
    "            day_importance_reg = reg_importance_df[reg_importance_df['Feature'].isin(day_features)]\n",
    "            print(f\"\\nDay of week feature importance for arrival delay regression in {year}:\")\n",
    "            print(day_importance_reg)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting regression feature importances: {e}\")\n",
    "        reg_importance_df = pd.DataFrame()\n",
    "    \n",
    "    # Step 14: Create visualization plots\n",
    "    \n",
    "    # Plot confusion matrix for classification model\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(class_cm, annot=True, fmt='d', cmap='Blues', \n",
    "               xticklabels=['Not Delayed', 'Delayed'],\n",
    "               yticklabels=['Not Delayed', 'Delayed'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Arrival Delay Classification Confusion Matrix ({year})')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(year_output_dir, 'plots', f'arrival_delay_confusion_matrix_{year}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot ROC curve for classification model\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    fpr, tpr, _ = roc_curve(y_test_class, y_prob_class)\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {class_roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve for Arrival Delay Classification ({year})')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(year_output_dir, 'plots', f'arrival_delay_roc_curve_{year}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot actual vs predicted delays for regression model\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Create a scatterplot with limited points for clarity\n",
    "    max_points = 5000\n",
    "    if len(y_test_reg) > max_points:\n",
    "        idx = np.random.choice(len(y_test_reg), max_points, replace=False)\n",
    "        sample_actual = y_test_reg.iloc[idx]\n",
    "        sample_pred = y_pred_reg[idx]\n",
    "    else:\n",
    "        sample_actual = y_test_reg\n",
    "        sample_pred = y_pred_reg\n",
    "    \n",
    "    plt.scatter(sample_actual, sample_pred, alpha=0.3)\n",
    "    \n",
    "    # Add perfect prediction line\n",
    "    max_val = max(sample_actual.max(), sample_pred.max())\n",
    "    min_val = min(sample_actual.min(), sample_pred.min())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "    \n",
    "    plt.xlabel('Actual Arrival Delay (minutes)')\n",
    "    plt.ylabel('Predicted Arrival Delay (minutes)')\n",
    "    plt.title(f'Actual vs Predicted Arrival Delay ({year})')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(year_output_dir, 'plots', f'arrival_delay_actual_vs_predicted_{year}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot delay by arrival time block if available\n",
    "    if 'ARR_TIME_BLOCK' in flight_data.columns:\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        time_delay = flight_data.groupby('ARR_TIME_BLOCK')['ARR_DELAY'].agg(['mean', 'count']).reset_index()\n",
    "        time_delay = time_delay.sort_values('mean', ascending=False)\n",
    "        \n",
    "        # Plot bar chart with both mean delay and flight count\n",
    "        ax1 = plt.subplot(111)\n",
    "        bars = sns.barplot(x='ARR_TIME_BLOCK', y='mean', data=time_delay, ax=ax1)\n",
    "        \n",
    "        # Annotate with mean delay values\n",
    "        for bar, mean in zip(bars.patches, time_delay['mean']):\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                    f'{mean:.1f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Create second y-axis for count\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(time_delay.index, time_delay['count'], 'ro-', linewidth=2)\n",
    "        \n",
    "        # Set labels and title\n",
    "        ax1.set_xlabel('Arrival Time Block')\n",
    "        ax1.set_ylabel('Mean Arrival Delay (minutes)')\n",
    "        ax2.set_ylabel('Number of Flights', color='r')\n",
    "        plt.title(f'Mean Arrival Delay by Time of Day ({year})')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(year_output_dir, 'plots', f'arrival_delay_by_time_{year}.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    # Plot delay by day of week from DAY_NAME column\n",
    "    if 'DAY_NAME' in flight_data.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "        \n",
    "        week_delay = flight_data.groupby('DAY_NAME')['ARR_DELAY'].mean().reset_index()\n",
    "        \n",
    "        # Ensure correct day order if all days are present\n",
    "        if all(day in week_delay['DAY_NAME'].values for day in day_order):\n",
    "            week_delay['DAY_NAME'] = pd.Categorical(week_delay['DAY_NAME'], categories=day_order, ordered=True)\n",
    "            week_delay = week_delay.sort_values('DAY_NAME')\n",
    "        \n",
    "        bars = sns.barplot(x='DAY_NAME', y='ARR_DELAY', data=week_delay)\n",
    "        \n",
    "        # Annotate with mean delay values\n",
    "        for bar, mean in zip(bars.patches, week_delay['ARR_DELAY']):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                    f'{mean:.1f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.xlabel('Day of Week')\n",
    "        plt.ylabel('Mean Arrival Delay (minutes)')\n",
    "        plt.title(f'Mean Arrival Delay by Day of Week ({year})')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(year_output_dir, 'plots', f'arrival_delay_by_week_{year}.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    # Create duration deviation analysis if available\n",
    "    if 'DURATION_DEVIATION' in flight_data.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Calculate mean arrival delay by duration deviation category\n",
    "        duration_delay = flight_data.groupby('DURATION_DEVIATION')['ARR_DELAY'].mean().reset_index()\n",
    "        \n",
    "        # Sort categories in a logical order\n",
    "        order = ['Much Faster', 'Faster', 'On Schedule', 'Slower', 'Much Slower', 'Extremely Slower']\n",
    "        order = [o for o in order if o in duration_delay['DURATION_DEVIATION'].values]\n",
    "        \n",
    "        duration_delay['DURATION_DEVIATION'] = pd.Categorical(\n",
    "            duration_delay['DURATION_DEVIATION'], \n",
    "            categories=order, \n",
    "            ordered=True\n",
    "        )\n",
    "        duration_delay = duration_delay.sort_values('DURATION_DEVIATION')\n",
    "        \n",
    "        bars = sns.barplot(x='DURATION_DEVIATION', y='ARR_DELAY', data=duration_delay)\n",
    "        \n",
    "        # Annotate with mean delay values\n",
    "        for bar, mean in zip(bars.patches, duration_delay['ARR_DELAY']):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                    f'{mean:.1f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.xlabel('Flight Duration Deviation')\n",
    "        plt.ylabel('Mean Arrival Delay (minutes)')\n",
    "        plt.title(f'Impact of Flight Duration on Arrival Delay ({year})')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(year_output_dir, 'plots', f'arrival_delay_by_duration_deviation_{year}.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    # Create heatmap of arrival delays by day and hour if available\n",
    "    if 'DAY_NAME' in flight_data.columns and 'ARR_HOUR' in flight_data.columns:\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        \n",
    "        # Create pivot table\n",
    "        day_hour_delay = flight_data.pivot_table(\n",
    "            values='ARR_DELAY',\n",
    "            index='DAY_NAME',\n",
    "            columns='ARR_HOUR',\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "        \n",
    "        # Reorder days to start with Monday\n",
    "        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "        day_hour_delay = day_hour_delay.reindex(day_order)\n",
    "        \n",
    "        # Create heatmap\n",
    "        sns.heatmap(day_hour_delay, cmap='YlOrRd', annot=True, fmt='.1f')\n",
    "        \n",
    "        plt.title(f'Mean Arrival Delay by Day and Hour ({year})')\n",
    "        plt.xlabel('Hour of Day')\n",
    "        plt.ylabel('Day of Week')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(year_output_dir, 'plots', f'arrival_delay_day_hour_heatmap_{year}.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    # Step 15: Save models\n",
    "    dump(final_class_model, os.path.join(year_output_dir, f\"arrival_delay_class_model_{year}.joblib\"))\n",
    "    dump(final_reg_model, os.path.join(year_output_dir, f\"arrival_delay_reg_model_{year}.joblib\"))\n",
    "    print(f\"Models saved to {year_output_dir}\")\n",
    "    \n",
    "    # Step 16: Create summary metrics\n",
    "    metrics = {\n",
    "        'model_name': f'arrival_delay_rf_{year}',\n",
    "        'year': year,\n",
    "        \n",
    "        # Dataset metrics\n",
    "        'total_flights': len(flight_data),\n",
    "        'arr_delayed_flights_rate': flight_data['IS_ARR_DELAYED'].mean() * 100,\n",
    "        'mean_arr_delay': flight_data['ARR_DELAY'].mean(),\n",
    "        'median_arr_delay': flight_data['ARR_DELAY'].median(),\n",
    "        'max_arr_delay': flight_data['ARR_DELAY'].max(),\n",
    "        'min_arr_delay': flight_data['ARR_DELAY'].min(),\n",
    "        \n",
    "        # Correlation metrics\n",
    "        'dep_arr_delay_correlation': corr_stats.get('delay_correlation', None),\n",
    "        'mean_delay_difference': corr_stats.get('mean_delay_diff', None),\n",
    "        'pct_arr_worse_than_dep': corr_stats.get('pct_arr_worse_than_dep', None),\n",
    "        \n",
    "        # Classification metrics\n",
    "        'class_accuracy': class_accuracy,\n",
    "        'class_roc_auc': class_roc_auc,\n",
    "        'class_precision': class_report['1']['precision'],\n",
    "        'class_recall': class_report['1']['recall'],\n",
    "        'class_f1': class_report['1']['f1-score'],\n",
    "        'class_training_time': class_model_training_time,\n",
    "        \n",
    "        # Regression metrics\n",
    "        'reg_mse': reg_mse,\n",
    "        'reg_rmse': reg_rmse,\n",
    "        'reg_mae': reg_mae,\n",
    "        'reg_r2': reg_r2,\n",
    "        'reg_training_time': reg_model_training_time,\n",
    "        \n",
    "        # Late night arrival metrics if available\n",
    "        'late_night_arr_count': flight_data['IS_LATE_NIGHT_ARR'].sum() if 'IS_LATE_NIGHT_ARR' in flight_data.columns else None,\n",
    "        'late_night_arr_pct': flight_data['IS_LATE_NIGHT_ARR'].mean() * 100 if 'IS_LATE_NIGHT_ARR' in flight_data.columns else None,\n",
    "        \n",
    "        'status': 'success',\n",
    "        'total_processing_time': time.time() - start_time\n",
    "    }\n",
    "    \n",
    "    # Save top important features for both models\n",
    "    if not class_importance_df.empty:\n",
    "        # Save top classification features\n",
    "        for i in range(min(10, len(class_importance_df))):\n",
    "            feat = class_importance_df.iloc[i]\n",
    "            metrics[f'class_top_feature_{i+1}'] = feat['Feature']\n",
    "            metrics[f'class_top_feature_{i+1}_importance'] = float(feat['Importance'])\n",
    "    \n",
    "    if not reg_importance_df.empty:\n",
    "        # Save top regression features\n",
    "        for i in range(min(10, len(reg_importance_df))):\n",
    "            feat = reg_importance_df.iloc[i]\n",
    "            metrics[f'reg_top_feature_{i+1}'] = feat['Feature']\n",
    "            metrics[f'reg_top_feature_{i+1}_importance'] = float(feat['Importance'])\n",
    "    \n",
    "    # Save day of week feature importance\n",
    "    if 'feature_names' in locals() and 'day_features' in locals():\n",
    "        if day_features:\n",
    "            metrics['day_features'] = day_features\n",
    "            \n",
    "            if 'day_importance' in locals() and not day_importance.empty:\n",
    "                metrics['day_importance_class'] = convert_to_serializable(day_importance.to_dict('records'))\n",
    "            \n",
    "            if 'day_importance_reg' in locals() and not day_importance_reg.empty:\n",
    "                metrics['day_importance_reg'] = convert_to_serializable(day_importance_reg.to_dict('records'))\n",
    "    \n",
    "    # Save metrics to JSON - using our serialization helper\n",
    "    import json\n",
    "    \n",
    "    # Convert to serializable format\n",
    "    serializable_metrics = convert_to_serializable(metrics)\n",
    "    with open(os.path.join(year_output_dir, 'metrics', f'arrival_delay_metrics_{year}.json'), 'w') as f:\n",
    "        json.dump(serializable_metrics, f, indent=4)\n",
    "    \n",
    "    print(f\"\\nArrival delay model training for {year} complete! Total processing time: {metrics['total_processing_time']:.2f} seconds\")\n",
    "    return metrics\n",
    "\n",
    "# Function to compare models across years\n",
    "def compare_year_models(all_results):\n",
    "    \"\"\"\n",
    "    Compare arrival delay models across different years\n",
    "    \n",
    "    Args:\n",
    "        all_results: Dictionary with results for each year\n",
    "        \n",
    "    Returns:\n",
    "        None (saves comparison plots)\n",
    "    \"\"\"\n",
    "    print(\"\\nComparing arrival delay models across years...\")\n",
    "    \n",
    "    if not all_results or len(all_results) < 2:\n",
    "        print(\"Not enough year models to compare.\")\n",
    "        return\n",
    "    \n",
    "    # Create a comparison directory\n",
    "    comparison_dir = os.path.join(output_dir, 'comparison')\n",
    "    os.makedirs(comparison_dir, exist_ok=True)\n",
    "    \n",
    "    # Extract years and sort them\n",
    "    years = sorted([r['year'] for r in all_results])\n",
    "    \n",
    "    # Create DataFrames for different metrics\n",
    "    class_metrics = pd.DataFrame({\n",
    "        'Year': years,\n",
    "        'Accuracy (%)': [r['class_accuracy'] for r in all_results],\n",
    "        'AUC': [r['class_roc_auc'] for r in all_results],\n",
    "        'Precision': [r['class_precision'] for r in all_results],\n",
    "        'Recall': [r['class_recall'] for r in all_results],\n",
    "        'F1 Score': [r['class_f1'] for r in all_results],\n",
    "    })\n",
    "    \n",
    "    reg_metrics = pd.DataFrame({\n",
    "        'Year': years,\n",
    "        'RMSE (min)': [r['reg_rmse'] for r in all_results],\n",
    "        'MAE (min)': [r['reg_mae'] for r in all_results],\n",
    "        'R² Score': [r['reg_r2'] for r in all_results],\n",
    "    })\n",
    "    \n",
    "    delay_stats = pd.DataFrame({\n",
    "        'Year': years,\n",
    "        'Mean Arrival Delay (min)': [r['mean_arr_delay'] for r in all_results],\n",
    "        'Arrival Delay Rate (%)': [r['arr_delayed_flights_rate'] for r in all_results],\n",
    "        'Total Flights': [r['total_flights'] for r in all_results],\n",
    "    })\n",
    "    \n",
    "    # Add correlation data if available\n",
    "    corr_data = []\n",
    "    for r in all_results:\n",
    "        if 'dep_arr_delay_correlation' in r and r['dep_arr_delay_correlation'] is not None:\n",
    "            corr_data.append({\n",
    "                'Year': r['year'],\n",
    "                'Correlation': r['dep_arr_delay_correlation'],\n",
    "                'Mean Diff (min)': r['mean_delay_difference'],\n",
    "                'Arrival Worse (%)': r['pct_arr_worse_than_dep']\n",
    "            })\n",
    "    \n",
    "    if corr_data:\n",
    "        corr_df = pd.DataFrame(corr_data)\n",
    "    \n",
    "    # 1. Plot classification metrics\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Set up bar positions\n",
    "    bar_width = 0.15\n",
    "    r1 = np.arange(len(years))\n",
    "    r2 = [x + bar_width for x in r1]\n",
    "    r3 = [x + bar_width for x in r2]\n",
    "    r4 = [x + bar_width for x in r3]\n",
    "    r5 = [x + bar_width for x in r4]\n",
    "    \n",
    "    # Create bars\n",
    "    plt.bar(r1, class_metrics['Accuracy (%)'] / 100, width=bar_width, label='Accuracy', color='blue')\n",
    "    plt.bar(r2, class_metrics['AUC'], width=bar_width, label='AUC', color='green')\n",
    "    plt.bar(r3, class_metrics['Precision'], width=bar_width, label='Precision', color='red')\n",
    "    plt.bar(r4, class_metrics['Recall'], width=bar_width, label='Recall', color='purple')\n",
    "    plt.bar(r5, class_metrics['F1 Score'], width=bar_width, label='F1 Score', color='orange')\n",
    "    \n",
    "    # Add texts on bars\n",
    "    for i, r in enumerate([r1, r2, r3, r4, r5]):\n",
    "        values = class_metrics.iloc[:, i+1].values\n",
    "        if i == 0:  # Accuracy needs to be multiplied by 100\n",
    "            values = values / 100\n",
    "        for j, v in enumerate(values):\n",
    "            plt.text(r[j], v + 0.01, f'{v:.2f}' if i > 0 else f'{v*100:.1f}%', \n",
    "                    ha='center', va='bottom', rotation=0, fontsize=8)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Arrival Delay Classification Metrics by Year')\n",
    "    plt.xticks([r + 2*bar_width for r in range(len(years))], years)\n",
    "    plt.legend()\n",
    "    plt.ylim(0, 1.0)  # Set y-axis limits for better visualization\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(comparison_dir, 'arrival_delay_class_metrics_by_year.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Plot regression metrics\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Plot RMSE and MAE\n",
    "    x = np.arange(len(years))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax1.bar(x - width/2, reg_metrics['RMSE (min)'], width, label='RMSE')\n",
    "    ax1.bar(x + width/2, reg_metrics['MAE (min)'], width, label='MAE')\n",
    "    \n",
    "    # Add text labels\n",
    "    for i, v in enumerate(reg_metrics['RMSE (min)']):\n",
    "        ax1.text(i - width/2, v + 0.5, f'{v:.1f}', ha='center', va='bottom')\n",
    "    for i, v in enumerate(reg_metrics['MAE (min)']):\n",
    "        ax1.text(i + width/2, v + 0.5, f'{v:.1f}', ha='center', va='bottom')\n",
    "    \n",
    "    ax1.set_xlabel('Year')\n",
    "    ax1.set_ylabel('Minutes')\n",
    "    ax1.set_title('Arrival Delay Regression Error Metrics')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(years)\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Plot R² Score\n",
    "    bars = ax2.bar(years, reg_metrics['R² Score'], color='green')\n",
    "    \n",
    "    # Add text labels\n",
    "    for bar, value in zip(bars, reg_metrics['R² Score']):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, value + 0.01, f'{value:.3f}', \n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    ax2.set_xlabel('Year')\n",
    "    ax2.set_ylabel('R² Score')\n",
    "    ax2.set_title('Arrival Delay Regression R² Score')\n",
    "    ax2.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(comparison_dir, 'arrival_delay_reg_metrics_by_year.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Plot delay statistics\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Plot mean delay\n",
    "    bars1 = ax1.bar(years, delay_stats['Mean Arrival Delay (min)'], color='blue')\n",
    "    \n",
    "    # Add text labels\n",
    "    for bar, value in zip(bars1, delay_stats['Mean Arrival Delay (min)']):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, value + 0.3, f'{value:.1f}', \n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    ax1.set_xlabel('Year')\n",
    "    ax1.set_ylabel('Minutes')\n",
    "    ax1.set_title('Mean Arrival Delay by Year')\n",
    "    ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Plot delay rate\n",
    "    bars2 = ax2.bar(years, delay_stats['Arrival Delay Rate (%)'], color='red')\n",
    "    \n",
    "    # Add text labels\n",
    "    for bar, value in zip(bars2, delay_stats['Arrival Delay Rate (%)']):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, value + 0.5, f'{value:.1f}%', \n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    ax2.set_xlabel('Year')\n",
    "    ax2.set_ylabel('Percentage')\n",
    "    ax2.set_title('Arrival Delay Rate by Year')\n",
    "    ax2.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(comparison_dir, 'arrival_delay_stats_by_year.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Plot correlation statistics if available\n",
    "    if corr_data:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        # Plot correlation coefficient\n",
    "        bars1 = ax1.bar(corr_df['Year'].astype(str), corr_df['Correlation'], color='purple')\n",
    "        \n",
    "        # Add text labels\n",
    "        for bar, value in zip(bars1, corr_df['Correlation']):\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2, value + 0.01, f'{value:.3f}', \n",
    "                    ha='center', va='bottom')\n",
    "        \n",
    "        ax1.set_xlabel('Year')\n",
    "        ax1.set_ylabel('Correlation Coefficient')\n",
    "        ax1.set_title('Departure-Arrival Delay Correlation by Year')\n",
    "        ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Plot percentage of flights where arrival delay is worse than departure\n",
    "        bars2 = ax2.bar(corr_df['Year'].astype(str), corr_df['Arrival Worse (%)'], color='orange')\n",
    "        \n",
    "        # Add text labels\n",
    "        for bar, value in zip(bars2, corr_df['Arrival Worse (%)']):\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2, value + 0.5, f'{value:.1f}%', \n",
    "                    ha='center', va='bottom')\n",
    "        \n",
    "        ax2.set_xlabel('Year')\n",
    "        ax2.set_ylabel('Percentage')\n",
    "        ax2.set_title('Flights Where Arrival Delay > Departure Delay')\n",
    "        ax2.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Save figure\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(comparison_dir, 'arrival_departure_correlation_by_year.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    # 5. Create a summary table for all metrics\n",
    "    summary_data = pd.concat([\n",
    "        delay_stats.set_index('Year'),\n",
    "        class_metrics.set_index('Year').iloc[:, 1:],  # Skip the Year column\n",
    "        reg_metrics.set_index('Year').iloc[:, 1:]     # Skip the Year column\n",
    "    ], axis=1)\n",
    "    \n",
    "    # Add correlation data if available\n",
    "    if corr_data:\n",
    "        corr_summary = corr_df.set_index('Year').iloc[:, :3]  # Get correlation columns\n",
    "        summary_data = pd.concat([summary_data, corr_summary], axis=1)\n",
    "    \n",
    "    # Save the summary to CSV\n",
    "    summary_data.to_csv(os.path.join(comparison_dir, 'arrival_delay_model_comparison.csv'))\n",
    "    print(f\"Comparison summary saved to {os.path.join(comparison_dir, 'arrival_delay_model_comparison.csv')}\")\n",
    "    \n",
    "    # 6. Create feature importance visualization across years\n",
    "    try:\n",
    "        # Collect top features for classification and regression\n",
    "        class_features_by_year = {}\n",
    "        reg_features_by_year = {}\n",
    "        \n",
    "        for result in all_results:\n",
    "            year = result['year']\n",
    "            \n",
    "            # Get classification features\n",
    "            class_features = []\n",
    "            for i in range(1, 6):  # Get top 5 features\n",
    "                feat_key = f'class_top_feature_{i}'\n",
    "                imp_key = f'class_top_feature_{i}_importance'\n",
    "                \n",
    "                if feat_key in result and imp_key in result:\n",
    "                    class_features.append({\n",
    "                        'feature': result[feat_key],\n",
    "                        'importance': result[imp_key]\n",
    "                    })\n",
    "            \n",
    "            if class_features:\n",
    "                class_features_by_year[year] = class_features\n",
    "            \n",
    "            # Get regression features\n",
    "            reg_features = []\n",
    "            for i in range(1, 6):  # Get top 5 features\n",
    "                feat_key = f'reg_top_feature_{i}'\n",
    "                imp_key = f'reg_top_feature_{i}_importance'\n",
    "                \n",
    "                if feat_key in result and imp_key in result:\n",
    "                    reg_features.append({\n",
    "                        'feature': result[feat_key],\n",
    "                        'importance': result[imp_key]\n",
    "                    })\n",
    "            \n",
    "            if reg_features:\n",
    "                reg_features_by_year[year] = reg_features\n",
    "        \n",
    "        # Create visualization function\n",
    "        def plot_top_features_by_year(features_by_year, model_type, output_path):\n",
    "            if not features_by_year:\n",
    "                return\n",
    "            \n",
    "            fig, axes = plt.subplots(len(features_by_year), 1, figsize=(12, 4*len(features_by_year)))\n",
    "            \n",
    "            # If there's only one year, we need to convert axes to a list\n",
    "            if len(features_by_year) == 1:\n",
    "                axes = [axes]\n",
    "            \n",
    "            for i, (year, features) in enumerate(sorted(features_by_year.items())):\n",
    "                # Extract feature names and importance values\n",
    "                feat_names = [f['feature'] for f in features]\n",
    "                importances = [f['importance'] for f in features]\n",
    "                \n",
    "                # Sort by importance\n",
    "                sorted_indices = np.argsort(importances)[::-1]  # Reverse to get descending order\n",
    "                feat_names = [feat_names[j] for j in sorted_indices]\n",
    "                importances = [importances[j] for j in sorted_indices]\n",
    "                \n",
    "                # Create horizontal bar chart\n",
    "                bars = axes[i].barh(range(len(feat_names)), importances, align='center')\n",
    "                \n",
    "                # Add value labels\n",
    "                for bar, value in zip(bars, importances):\n",
    "                    axes[i].text(value + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                              f'{value:.3f}', va='center')\n",
    "                \n",
    "                # Set y-ticks and labels\n",
    "                axes[i].set_yticks(range(len(feat_names)))\n",
    "                axes[i].set_yticklabels(feat_names)\n",
    "                \n",
    "                # Set title\n",
    "                axes[i].set_title(f'Year {year}')\n",
    "                \n",
    "                # Set x-label only for the bottom subplot\n",
    "                if i == len(features_by_year) - 1:\n",
    "                    axes[i].set_xlabel('Feature Importance')\n",
    "            \n",
    "            plt.suptitle(f'Top 5 Most Important Features for Arrival Delay {model_type.title()} by Year', \n",
    "                        fontsize=16, y=1.02)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        \n",
    "        # Plot top features for classification and regression\n",
    "        plot_top_features_by_year(\n",
    "            class_features_by_year, \n",
    "            'classification',\n",
    "            os.path.join(comparison_dir, 'arrival_delay_class_top_features_by_year.png')\n",
    "        )\n",
    "        \n",
    "        plot_top_features_by_year(\n",
    "            reg_features_by_year, \n",
    "            'regression',\n",
    "            os.path.join(comparison_dir, 'arrival_delay_reg_top_features_by_year.png')\n",
    "        )\n",
    "        \n",
    "        # Save feature info to JSON\n",
    "        features_data = {\n",
    "            'classification': class_features_by_year,\n",
    "            'regression': reg_features_by_year\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(comparison_dir, 'arrival_delay_feature_importance_by_year.json'), 'w') as f:\n",
    "            json.dump(convert_to_serializable(features_data), f, indent=4)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating feature importance visualization: {e}\")\n",
    "    \n",
    "    print(\"Arrival delay model comparison completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Training Arrival Delay model for year 2021\n",
      "================================================================================\n",
      "\n",
      "Processing May2021.csv...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years found in data: [2021]\n",
      "Months found in data: {5: 520059}\n",
      "Filtered to only May data: 520059 rows\n",
      "Filtered from 520059 to 171867 rows for top 30 airports\n",
      "Removed 485.0 cancelled flights, remaining: 171382\n",
      "Removed 482.0 diverted flights, remaining: 170900\n",
      "Processing took: 2.80 seconds\n",
      "\n",
      "Matching origin weather data with flights...\n",
      "Processed 10000/170900 rows, matched 7634 flights with origin weather data\n",
      "Processed 20000/170900 rows, matched 15264 flights with origin weather data\n",
      "Processed 30000/170900 rows, matched 22827 flights with origin weather data\n",
      "Processed 40000/170900 rows, matched 30384 flights with origin weather data\n",
      "Processed 50000/170900 rows, matched 37950 flights with origin weather data\n",
      "Processed 60000/170900 rows, matched 45641 flights with origin weather data\n",
      "Processed 70000/170900 rows, matched 53248 flights with origin weather data\n",
      "Processed 80000/170900 rows, matched 60891 flights with origin weather data\n",
      "Processed 90000/170900 rows, matched 68409 flights with origin weather data\n",
      "Processed 100000/170900 rows, matched 76001 flights with origin weather data\n",
      "Processed 110000/170900 rows, matched 83596 flights with origin weather data\n",
      "Processed 120000/170900 rows, matched 91321 flights with origin weather data\n",
      "Processed 130000/170900 rows, matched 98782 flights with origin weather data\n",
      "Processed 140000/170900 rows, matched 106412 flights with origin weather data\n",
      "Processed 150000/170900 rows, matched 113960 flights with origin weather data\n",
      "Processed 160000/170900 rows, matched 121688 flights with origin weather data\n",
      "Processed 170000/170900 rows, matched 129293 flights with origin weather data\n",
      "Processed 170900/170900 rows, matched 130036 flights with origin weather data\n",
      "Matched origin weather data for 130036 flights (76.09%)\n",
      "Origin weather matching took: 63.05 seconds\n",
      "\n",
      "Matching destination weather data with flights...\n",
      "Processed 10000/170900 rows, matched 7619 flights with destination weather data\n",
      "Processed 20000/170900 rows, matched 15269 flights with destination weather data\n",
      "Processed 30000/170900 rows, matched 22847 flights with destination weather data\n",
      "Processed 40000/170900 rows, matched 30395 flights with destination weather data\n",
      "Processed 50000/170900 rows, matched 37968 flights with destination weather data\n",
      "Processed 60000/170900 rows, matched 45695 flights with destination weather data\n",
      "Processed 70000/170900 rows, matched 53301 flights with destination weather data\n",
      "Processed 80000/170900 rows, matched 60950 flights with destination weather data\n",
      "Processed 90000/170900 rows, matched 68461 flights with destination weather data\n",
      "Processed 100000/170900 rows, matched 76055 flights with destination weather data\n",
      "Processed 110000/170900 rows, matched 83643 flights with destination weather data\n",
      "Processed 120000/170900 rows, matched 91362 flights with destination weather data\n",
      "Processed 130000/170900 rows, matched 98827 flights with destination weather data\n",
      "Processed 140000/170900 rows, matched 106465 flights with destination weather data\n",
      "Processed 150000/170900 rows, matched 114036 flights with destination weather data\n",
      "Processed 160000/170900 rows, matched 121746 flights with destination weather data\n",
      "Processed 170000/170900 rows, matched 129349 flights with destination weather data\n",
      "Processed 170900/170900 rows, matched 130095 flights with destination weather data\n",
      "Matched destination weather data for 130095 flights (76.12%)\n",
      "Destination weather matching took: 63.78 seconds\n",
      "\n",
      "Analyzing correlation between departure and arrival delays...\n",
      "Correlation between departure and arrival delays: 0.9462\n",
      "Mean difference (ARR_DELAY - DEP_DELAY): -8.64 minutes\n",
      "Median difference: -10.00 minutes\n",
      "Flights where arrival delay > departure delay: 32200 (18.8%)\n",
      "Flights where arrival delay < departure delay: 134984 (79.0%)\n",
      "\n",
      "Creating late-night arrival indicator for 2021...\n",
      "Identified 22128 late-night arrivals (22:00-06:00)\n",
      "Total identified late-night arrivals: 22128 out of 170900 total flights (12.95%)\n",
      "\n",
      "Distribution of flights by arrival time of day:\n",
      "  - Afternoon (12-18): 61931 flights (36.24%)\n",
      "  - Morning (6-12): 44684 flights (26.15%)\n",
      "  - Evening (18-22): 42549 flights (24.90%)\n",
      "  - Night (22-24): 17017 flights (9.96%)\n",
      "  - Early Morning (0-6): 4719 flights (2.76%)\n",
      "\n",
      "Preparing arrival delay data for 2021...\n",
      "\n",
      "Arrival delay statistics:\n",
      "Delayed arrivals: 46474/170900 (27.19%)\n",
      "On-time or early arrivals: 124426/170900 (72.81%)\n",
      "\n",
      "Arrival delay magnitude statistics:\n",
      "Mean arrival delay: -1.71 minutes\n",
      "Median arrival delay: -9.00 minutes\n",
      "Min arrival delay: -107.00 minutes (negative means early arrival)\n",
      "Max arrival delay: 1793.00 minutes\n",
      "\n",
      "Arrival delay category distribution:\n",
      "  - Very Early: 58626 flights (34.30%)\n",
      "  - Early: 65800 flights (38.50%)\n",
      "  - On Time: 25146 flights (14.71%)\n",
      "  - Slight Delay: 8504 flights (4.98%)\n",
      "  - Moderate Delay: 6183 flights (3.62%)\n",
      "  - Significant Delay: 3920 flights (2.29%)\n",
      "  - Severe Delay: 2721 flights (1.59%)\n",
      "\n",
      "Flights with arrival delay worse than departure delay: 32200/170900 (18.84%)\n",
      "\n",
      "Creating arrival time block features for 2021...\n",
      "\n",
      "Creating day features for 2021...\n",
      "\n",
      "Distribution of flights by day of week:\n",
      "  - Monday: 28712 flights (16.80%)\n",
      "  - Sunday: 28336 flights (16.58%)\n",
      "  - Saturday: 25856 flights (15.13%)\n",
      "  - Friday: 23466 flights (13.73%)\n",
      "  - Thursday: 23261 flights (13.61%)\n",
      "  - Wednesday: 20970 flights (12.27%)\n",
      "  - Tuesday: 20299 flights (11.88%)\n",
      "\n",
      "Weekend flights: 54192 (31.71%)\n",
      "Weekday flights: 116708 (68.29%)\n",
      "\n",
      "Creating flight duration features for 2021...\n",
      "\n",
      "Flight duration statistics:\n",
      "Mean scheduled duration: 189.6 minutes\n",
      "Mean actual duration: 186.0 minutes\n",
      "Mean duration difference: -3.6 minutes\n",
      "Flights faster than scheduled: 104450 (61.1%)\n",
      "Flights slower than scheduled: 63534 (37.2%)\n",
      "\n",
      "Flight duration deviation distribution:\n",
      "  - Much Faster: 53356 flights (31.22%)\n",
      "  - Faster: 37584 flights (21.99%)\n",
      "  - On Schedule: 27264 flights (15.95%)\n",
      "  - Slower: 11261 flights (6.59%)\n",
      "  - Much Slower: 22371 flights (13.09%)\n",
      "  - Extremely Slower: 19064 flights (11.16%)\n",
      "\n",
      "Flight distance distribution:\n",
      "  - Very Short (<300 mi): 11803 flights (6.91%)\n",
      "  - Short (300-600 mi): 30812 flights (18.03%)\n",
      "  - Medium (600-1000 mi): 53672 flights (31.41%)\n",
      "  - Long (1000-1500 mi): 38879 flights (22.75%)\n",
      "  - Very Long (>1500 mi): 35734 flights (20.91%)\n",
      "\n",
      "Selecting features for arrival delay prediction for 2021...\n",
      "Using categorical features: ['DAY_NAME', 'ARR_TIME_BLOCK', 'MKT_AIRLINE', 'ORIGIN_IATA', 'DEST_IATA', 'FLIGHT_DISTANCE_CAT', 'DURATION_DEVIATION', 'IS_LATE_NIGHT_ARR', 'IS_WEEKEND', 'IS_MORNING_RUSH_ARR', 'IS_EVENING_RUSH_ARR', 'EXTREME_WEATHER', 'DEST_EXTREME_WEATHER']\n",
      "Using numerical features: ['DISTANCE', 'SCH_DURATION_MINS', 'PRCP', 'DEST_PRCP', 'DEP_DELAY']\n",
      "Training set size: (128175, 18)\n",
      "Test set size: (42725, 18)\n",
      "\n",
      "Training arrival delay classification model for 2021 (Random Forest)...\n",
      "Arrival delay classification model training took: 23.09 seconds\n",
      "\n",
      "Training arrival delay regression model for 2021 (Random Forest)...\n",
      "Arrival delay regression model training took: 247.73 seconds\n",
      "\n",
      "Evaluating arrival delay classification model for 2021...\n",
      "Arrival Delay Classification Accuracy: 88.48%\n",
      "Arrival Delay Classification ROC AUC: 0.9477\n",
      "Arrival Delay Classification Precision (Delayed): 0.7651\n",
      "Arrival Delay Classification Recall (Delayed): 0.8319\n",
      "Arrival Delay Classification F1 Score (Delayed): 0.7971\n",
      "\n",
      "Evaluating arrival delay regression model for 2021...\n",
      "Arrival Delay Regression Mean Squared Error: 105.70\n",
      "Arrival Delay Regression Root Mean Squared Error: 10.28 minutes\n",
      "Arrival Delay Regression Mean Absolute Error: 6.34 minutes\n",
      "Arrival Delay Regression R² Score: 0.9386\n",
      "Feature importance plot saved to ./rf_arrival_delay_models/year_2021\\plots\\arrival_delay_class_feature_importance_2021.png\n",
      "\n",
      "Top 10 most important features for arrival delay classification in 2021:\n",
      "                                     Feature  Importance\n",
      "4                             num__DEP_DELAY    0.562029\n",
      "99            cat__DURATION_DEVIATION_Slower    0.069622\n",
      "95            cat__DURATION_DEVIATION_Faster    0.040085\n",
      "94  cat__DURATION_DEVIATION_Extremely Slower    0.031563\n",
      "96       cat__DURATION_DEVIATION_Much Faster    0.028726\n",
      "1                     num__SCH_DURATION_MINS    0.023330\n",
      "0                              num__DISTANCE    0.023136\n",
      "98       cat__DURATION_DEVIATION_On Schedule    0.017737\n",
      "2                                  num__PRCP    0.013953\n",
      "3                             num__DEST_PRCP    0.012543\n",
      "\n",
      "Day of week feature importance for arrival delay classification in 2021:\n",
      "                    Feature  Importance\n",
      "10    cat__DAY_NAME_Tuesday    0.002397\n",
      "6      cat__DAY_NAME_Monday    0.002245\n",
      "5      cat__DAY_NAME_Friday    0.002164\n",
      "11  cat__DAY_NAME_Wednesday    0.002118\n",
      "8      cat__DAY_NAME_Sunday    0.001986\n",
      "9    cat__DAY_NAME_Thursday    0.001931\n",
      "7    cat__DAY_NAME_Saturday    0.001917\n",
      "Feature importance plot saved to ./rf_arrival_delay_models/year_2021\\plots\\arrival_delay_reg_feature_importance_2021.png\n",
      "\n",
      "Top 10 most important features for arrival delay regression in 2021:\n",
      "                                     Feature  Importance\n",
      "4                             num__DEP_DELAY    0.935945\n",
      "96       cat__DURATION_DEVIATION_Much Faster    0.014005\n",
      "94  cat__DURATION_DEVIATION_Extremely Slower    0.007002\n",
      "1                     num__SCH_DURATION_MINS    0.005544\n",
      "0                              num__DISTANCE    0.004991\n",
      "97       cat__DURATION_DEVIATION_Much Slower    0.004819\n",
      "95            cat__DURATION_DEVIATION_Faster    0.004473\n",
      "3                             num__DEST_PRCP    0.002703\n",
      "2                                  num__PRCP    0.001675\n",
      "98       cat__DURATION_DEVIATION_On Schedule    0.001385\n",
      "\n",
      "Day of week feature importance for arrival delay regression in 2021:\n",
      "                    Feature  Importance\n",
      "10    cat__DAY_NAME_Tuesday    0.000413\n",
      "6      cat__DAY_NAME_Monday    0.000294\n",
      "9    cat__DAY_NAME_Thursday    0.000212\n",
      "5      cat__DAY_NAME_Friday    0.000181\n",
      "8      cat__DAY_NAME_Sunday    0.000149\n",
      "11  cat__DAY_NAME_Wednesday    0.000136\n",
      "7    cat__DAY_NAME_Saturday    0.000131\n",
      "Models saved to ./rf_arrival_delay_models/year_2021\n",
      "\n",
      "Arrival delay model training for 2021 complete! Total processing time: 404.78 seconds\n",
      "\n",
      "Arrival delay model for year 2021 completed successfully!\n",
      "\n",
      "================================================================================\n",
      "Training Arrival Delay model for year 2022\n",
      "================================================================================\n",
      "\n",
      "Processing May2022.csv...\n",
      "Years found in data: [2022]\n",
      "Months found in data: {5: 602950}\n",
      "Filtered to only May data: 602950 rows\n",
      "Filtered from 602950 to 210079 rows for top 30 airports\n",
      "Removed 4659.0 cancelled flights, remaining: 205420\n",
      "Processing took: 3.18 seconds\n",
      "\n",
      "Matching origin weather data with flights...\n",
      "Processed 10000/205420 rows, matched 7065 flights with origin weather data\n",
      "Processed 20000/205420 rows, matched 14381 flights with origin weather data\n",
      "Processed 30000/205420 rows, matched 21409 flights with origin weather data\n",
      "Processed 40000/205420 rows, matched 28736 flights with origin weather data\n",
      "Processed 50000/205420 rows, matched 35905 flights with origin weather data\n",
      "Processed 60000/205420 rows, matched 43280 flights with origin weather data\n",
      "Processed 70000/205420 rows, matched 50286 flights with origin weather data\n",
      "Processed 80000/205420 rows, matched 57605 flights with origin weather data\n",
      "Processed 90000/205420 rows, matched 64757 flights with origin weather data\n",
      "Processed 100000/205420 rows, matched 72193 flights with origin weather data\n",
      "Processed 110000/205420 rows, matched 79374 flights with origin weather data\n",
      "Processed 120000/205420 rows, matched 86687 flights with origin weather data\n",
      "Processed 130000/205420 rows, matched 93773 flights with origin weather data\n",
      "Processed 140000/205420 rows, matched 101221 flights with origin weather data\n",
      "Processed 150000/205420 rows, matched 108364 flights with origin weather data\n",
      "Processed 160000/205420 rows, matched 115722 flights with origin weather data\n",
      "Processed 170000/205420 rows, matched 122731 flights with origin weather data\n",
      "Processed 180000/205420 rows, matched 130269 flights with origin weather data\n",
      "Processed 190000/205420 rows, matched 137386 flights with origin weather data\n",
      "Processed 200000/205420 rows, matched 144660 flights with origin weather data\n",
      "Processed 205420/205420 rows, matched 148501 flights with origin weather data\n",
      "Matched origin weather data for 148501 flights (72.29%)\n",
      "Origin weather matching took: 72.47 seconds\n",
      "\n",
      "Matching destination weather data with flights...\n",
      "Processed 10000/205420 rows, matched 7044 flights with destination weather data\n",
      "Processed 20000/205420 rows, matched 14362 flights with destination weather data\n",
      "Processed 30000/205420 rows, matched 21368 flights with destination weather data\n",
      "Processed 40000/205420 rows, matched 28726 flights with destination weather data\n",
      "Processed 50000/205420 rows, matched 35884 flights with destination weather data\n",
      "Processed 60000/205420 rows, matched 43262 flights with destination weather data\n",
      "Processed 70000/205420 rows, matched 50256 flights with destination weather data\n",
      "Processed 80000/205420 rows, matched 57582 flights with destination weather data\n",
      "Processed 90000/205420 rows, matched 64735 flights with destination weather data\n",
      "Processed 100000/205420 rows, matched 72170 flights with destination weather data\n",
      "Processed 110000/205420 rows, matched 79353 flights with destination weather data\n",
      "Processed 120000/205420 rows, matched 86663 flights with destination weather data\n",
      "Processed 130000/205420 rows, matched 93734 flights with destination weather data\n",
      "Processed 140000/205420 rows, matched 101195 flights with destination weather data\n",
      "Processed 150000/205420 rows, matched 108325 flights with destination weather data\n",
      "Processed 160000/205420 rows, matched 115678 flights with destination weather data\n",
      "Processed 170000/205420 rows, matched 122688 flights with destination weather data\n",
      "Processed 180000/205420 rows, matched 130232 flights with destination weather data\n",
      "Processed 190000/205420 rows, matched 137350 flights with destination weather data\n",
      "Processed 200000/205420 rows, matched 144591 flights with destination weather data\n",
      "Processed 205420/205420 rows, matched 148450 flights with destination weather data\n",
      "Matched destination weather data for 148450 flights (72.27%)\n",
      "Destination weather matching took: 73.64 seconds\n",
      "\n",
      "Analyzing correlation between departure and arrival delays...\n",
      "Correlation between departure and arrival delays: 0.9608\n",
      "Mean difference (ARR_DELAY - DEP_DELAY): -5.94 minutes\n",
      "Median difference: -7.00 minutes\n",
      "Flights where arrival delay > departure delay: 51021 (24.8%)\n",
      "Flights where arrival delay < departure delay: 148844 (72.5%)\n",
      "\n",
      "Creating late-night arrival indicator for 2022...\n",
      "Identified 29648 late-night arrivals (22:00-06:00)\n",
      "Total identified late-night arrivals: 29648 out of 205420 total flights (14.43%)\n",
      "\n",
      "Distribution of flights by arrival time of day:\n",
      "  - Afternoon (12-18): 69749 flights (33.95%)\n",
      "  - Morning (6-12): 57368 flights (27.93%)\n",
      "  - Evening (18-22): 49134 flights (23.92%)\n",
      "  - Night (22-24): 21408 flights (10.42%)\n",
      "  - Early Morning (0-6): 7761 flights (3.78%)\n",
      "\n",
      "Preparing arrival delay data for 2022...\n",
      "\n",
      "Arrival delay statistics:\n",
      "Delayed arrivals: 82986/205420 (40.40%)\n",
      "On-time or early arrivals: 122434/205420 (59.60%)\n",
      "\n",
      "Arrival delay magnitude statistics:\n",
      "Mean arrival delay: 8.59 minutes\n",
      "Median arrival delay: -4.00 minutes\n",
      "Min arrival delay: -81.00 minutes (negative means early arrival)\n",
      "Max arrival delay: 2090.00 minutes\n",
      "\n",
      "Arrival delay category distribution:\n",
      "  - Very Early: 48176 flights (23.45%)\n",
      "  - Early: 73680 flights (35.87%)\n",
      "  - On Time: 36848 flights (17.94%)\n",
      "  - Slight Delay: 16340 flights (7.95%)\n",
      "  - Moderate Delay: 14464 flights (7.04%)\n",
      "  - Significant Delay: 9468 flights (4.61%)\n",
      "  - Severe Delay: 5866 flights (2.86%)\n",
      "\n",
      "Flights with arrival delay worse than departure delay: 51021/205420 (24.84%)\n",
      "\n",
      "Creating arrival time block features for 2022...\n",
      "\n",
      "Creating day features for 2022...\n",
      "\n",
      "Distribution of flights by day of week:\n",
      "  - Monday: 34057 flights (16.58%)\n",
      "  - Tuesday: 33242 flights (16.18%)\n",
      "  - Sunday: 33153 flights (16.14%)\n",
      "  - Thursday: 28003 flights (13.63%)\n",
      "  - Friday: 26923 flights (13.11%)\n",
      "  - Wednesday: 26859 flights (13.08%)\n",
      "  - Saturday: 23183 flights (11.29%)\n",
      "\n",
      "Weekend flights: 56336 (27.42%)\n",
      "Weekday flights: 149084 (72.58%)\n",
      "\n",
      "Creating flight duration features for 2022...\n",
      "\n",
      "Flight duration statistics:\n",
      "Mean scheduled duration: 188.7 minutes\n",
      "Mean actual duration: 187.3 minutes\n",
      "Mean duration difference: -1.4 minutes\n",
      "Flights faster than scheduled: 120944 (58.9%)\n",
      "Flights slower than scheduled: 80544 (39.2%)\n",
      "\n",
      "Flight duration deviation distribution:\n",
      "  - Much Faster: 58906 flights (28.68%)\n",
      "  - Faster: 44416 flights (21.62%)\n",
      "  - On Schedule: 36238 flights (17.64%)\n",
      "  - Slower: 14491 flights (7.05%)\n",
      "  - Much Slower: 23598 flights (11.49%)\n",
      "  - Extremely Slower: 27727 flights (13.50%)\n",
      "\n",
      "Flight distance distribution:\n",
      "  - Very Short (<300 mi): 19306 flights (9.40%)\n",
      "  - Short (300-600 mi): 36149 flights (17.60%)\n",
      "  - Medium (600-1000 mi): 64020 flights (31.17%)\n",
      "  - Long (1000-1500 mi): 42738 flights (20.81%)\n",
      "  - Very Long (>1500 mi): 43207 flights (21.03%)\n",
      "\n",
      "Selecting features for arrival delay prediction for 2022...\n",
      "Using categorical features: ['DAY_NAME', 'ARR_TIME_BLOCK', 'MKT_AIRLINE', 'ORIGIN_IATA', 'DEST_IATA', 'FLIGHT_DISTANCE_CAT', 'DURATION_DEVIATION', 'IS_LATE_NIGHT_ARR', 'IS_WEEKEND', 'IS_MORNING_RUSH_ARR', 'IS_EVENING_RUSH_ARR', 'EXTREME_WEATHER', 'DEST_EXTREME_WEATHER']\n",
      "Using numerical features: ['DISTANCE', 'SCH_DURATION_MINS', 'PRCP', 'DEST_PRCP', 'DEP_DELAY']\n",
      "Warning: Found 578 NaN values in ARR_DELAY. Removing these records.\n",
      "After removing NaN values, remaining records: 204842\n",
      "Training set size: (153631, 18)\n",
      "Test set size: (51211, 18)\n",
      "\n",
      "Training arrival delay classification model for 2022 (Random Forest)...\n",
      "Arrival delay classification model training took: 34.21 seconds\n",
      "\n",
      "Training arrival delay regression model for 2022 (Random Forest)...\n",
      "Arrival delay regression model training took: 441.61 seconds\n",
      "\n",
      "Evaluating arrival delay classification model for 2022...\n",
      "Arrival Delay Classification Accuracy: 88.16%\n",
      "Arrival Delay Classification ROC AUC: 0.9505\n",
      "Arrival Delay Classification Precision (Delayed): 0.8662\n",
      "Arrival Delay Classification Recall (Delayed): 0.8370\n",
      "Arrival Delay Classification F1 Score (Delayed): 0.8514\n",
      "\n",
      "Evaluating arrival delay regression model for 2022...\n",
      "Arrival Delay Regression Mean Squared Error: 139.92\n",
      "Arrival Delay Regression Root Mean Squared Error: 11.83 minutes\n",
      "Arrival Delay Regression Mean Absolute Error: 6.99 minutes\n",
      "Arrival Delay Regression R² Score: 0.9560\n",
      "Feature importance plot saved to ./rf_arrival_delay_models/year_2022\\plots\\arrival_delay_class_feature_importance_2022.png\n",
      "\n",
      "Top 10 most important features for arrival delay classification in 2022:\n",
      "                                     Feature  Importance\n",
      "4                             num__DEP_DELAY    0.604404\n",
      "99            cat__DURATION_DEVIATION_Slower    0.062441\n",
      "95            cat__DURATION_DEVIATION_Faster    0.041393\n",
      "94  cat__DURATION_DEVIATION_Extremely Slower    0.032423\n",
      "96       cat__DURATION_DEVIATION_Much Faster    0.027754\n",
      "1                     num__SCH_DURATION_MINS    0.019622\n",
      "0                              num__DISTANCE    0.018033\n",
      "98       cat__DURATION_DEVIATION_On Schedule    0.015937\n",
      "2                                  num__PRCP    0.007950\n",
      "97       cat__DURATION_DEVIATION_Much Slower    0.007145\n",
      "\n",
      "Day of week feature importance for arrival delay classification in 2022:\n",
      "                    Feature  Importance\n",
      "5      cat__DAY_NAME_Friday    0.003660\n",
      "10    cat__DAY_NAME_Tuesday    0.003288\n",
      "11  cat__DAY_NAME_Wednesday    0.001988\n",
      "6      cat__DAY_NAME_Monday    0.001560\n",
      "9    cat__DAY_NAME_Thursday    0.001542\n",
      "8      cat__DAY_NAME_Sunday    0.001338\n",
      "7    cat__DAY_NAME_Saturday    0.001097\n",
      "Feature importance plot saved to ./rf_arrival_delay_models/year_2022\\plots\\arrival_delay_reg_feature_importance_2022.png\n",
      "\n",
      "Top 10 most important features for arrival delay regression in 2022:\n",
      "                                     Feature  Importance\n",
      "4                             num__DEP_DELAY    0.951269\n",
      "94  cat__DURATION_DEVIATION_Extremely Slower    0.009198\n",
      "96       cat__DURATION_DEVIATION_Much Faster    0.008465\n",
      "1                     num__SCH_DURATION_MINS    0.005698\n",
      "0                              num__DISTANCE    0.004415\n",
      "99            cat__DURATION_DEVIATION_Slower    0.001747\n",
      "98       cat__DURATION_DEVIATION_On Schedule    0.001664\n",
      "3                             num__DEST_PRCP    0.001275\n",
      "2                                  num__PRCP    0.001028\n",
      "95            cat__DURATION_DEVIATION_Faster    0.000831\n",
      "\n",
      "Day of week feature importance for arrival delay regression in 2022:\n",
      "                    Feature  Importance\n",
      "5      cat__DAY_NAME_Friday    0.000556\n",
      "9    cat__DAY_NAME_Thursday    0.000200\n",
      "6      cat__DAY_NAME_Monday    0.000170\n",
      "8      cat__DAY_NAME_Sunday    0.000168\n",
      "10    cat__DAY_NAME_Tuesday    0.000151\n",
      "7    cat__DAY_NAME_Saturday    0.000147\n",
      "11  cat__DAY_NAME_Wednesday    0.000138\n",
      "Models saved to ./rf_arrival_delay_models/year_2022\n",
      "\n",
      "Arrival delay model training for 2022 complete! Total processing time: 630.18 seconds\n",
      "\n",
      "Arrival delay model for year 2022 completed successfully!\n",
      "\n",
      "================================================================================\n",
      "Training Arrival Delay model for year 2023\n",
      "================================================================================\n",
      "\n",
      "Processing May2023.csv...\n",
      "Years found in data: [2023]\n",
      "Months found in data: {5: 616630}\n",
      "Filtered to only May data: 616630 rows\n",
      "Filtered from 616630 to 220469 rows for top 30 airports\n",
      "Removed 1293.0 cancelled flights, remaining: 219176\n",
      "Processing took: 4.47 seconds\n",
      "\n",
      "Matching origin weather data with flights...\n",
      "Processed 10000/219176 rows, matched 7071 flights with origin weather data\n",
      "Processed 20000/219176 rows, matched 14364 flights with origin weather data\n",
      "Processed 30000/219176 rows, matched 21626 flights with origin weather data\n",
      "Processed 40000/219176 rows, matched 28902 flights with origin weather data\n",
      "Processed 50000/219176 rows, matched 36373 flights with origin weather data\n",
      "Processed 60000/219176 rows, matched 43539 flights with origin weather data\n",
      "Processed 70000/219176 rows, matched 50884 flights with origin weather data\n",
      "Processed 80000/219176 rows, matched 58144 flights with origin weather data\n",
      "Processed 90000/219176 rows, matched 65463 flights with origin weather data\n",
      "Processed 100000/219176 rows, matched 72856 flights with origin weather data\n",
      "Processed 110000/219176 rows, matched 79891 flights with origin weather data\n",
      "Processed 120000/219176 rows, matched 86951 flights with origin weather data\n",
      "Processed 130000/219176 rows, matched 93797 flights with origin weather data\n",
      "Processed 140000/219176 rows, matched 101252 flights with origin weather data\n",
      "Processed 150000/219176 rows, matched 108560 flights with origin weather data\n",
      "Processed 160000/219176 rows, matched 115748 flights with origin weather data\n",
      "Processed 170000/219176 rows, matched 123276 flights with origin weather data\n",
      "Processed 180000/219176 rows, matched 130383 flights with origin weather data\n",
      "Processed 190000/219176 rows, matched 137913 flights with origin weather data\n",
      "Processed 200000/219176 rows, matched 145101 flights with origin weather data\n",
      "Processed 210000/219176 rows, matched 152449 flights with origin weather data\n",
      "Processed 219176/219176 rows, matched 159344 flights with origin weather data\n",
      "Matched origin weather data for 159344 flights (72.70%)\n",
      "Origin weather matching took: 80.20 seconds\n",
      "\n",
      "Matching destination weather data with flights...\n",
      "Processed 10000/219176 rows, matched 7056 flights with destination weather data\n",
      "Processed 20000/219176 rows, matched 14352 flights with destination weather data\n",
      "Processed 30000/219176 rows, matched 21628 flights with destination weather data\n",
      "Processed 40000/219176 rows, matched 28897 flights with destination weather data\n",
      "Processed 50000/219176 rows, matched 36378 flights with destination weather data\n",
      "Processed 60000/219176 rows, matched 43542 flights with destination weather data\n",
      "Processed 70000/219176 rows, matched 50886 flights with destination weather data\n",
      "Processed 80000/219176 rows, matched 58142 flights with destination weather data\n",
      "Processed 90000/219176 rows, matched 65466 flights with destination weather data\n",
      "Processed 100000/219176 rows, matched 72847 flights with destination weather data\n",
      "Processed 110000/219176 rows, matched 79889 flights with destination weather data\n",
      "Processed 120000/219176 rows, matched 86940 flights with destination weather data\n",
      "Processed 130000/219176 rows, matched 93797 flights with destination weather data\n",
      "Processed 140000/219176 rows, matched 101252 flights with destination weather data\n",
      "Processed 150000/219176 rows, matched 108557 flights with destination weather data\n",
      "Processed 160000/219176 rows, matched 115745 flights with destination weather data\n",
      "Processed 170000/219176 rows, matched 123276 flights with destination weather data\n",
      "Processed 180000/219176 rows, matched 130394 flights with destination weather data\n",
      "Processed 190000/219176 rows, matched 137918 flights with destination weather data\n",
      "Processed 200000/219176 rows, matched 145106 flights with destination weather data\n",
      "Processed 210000/219176 rows, matched 152448 flights with destination weather data\n",
      "Processed 219176/219176 rows, matched 159341 flights with destination weather data\n",
      "Matched destination weather data for 159341 flights (72.70%)\n",
      "Destination weather matching took: 77.48 seconds\n",
      "\n",
      "Analyzing correlation between departure and arrival delays...\n",
      "Correlation between departure and arrival delays: 0.9633\n",
      "Mean difference (ARR_DELAY - DEP_DELAY): -7.10 minutes\n",
      "Median difference: -8.00 minutes\n",
      "Flights where arrival delay > departure delay: 50024 (22.8%)\n",
      "Flights where arrival delay < departure delay: 163474 (74.6%)\n",
      "\n",
      "Creating late-night arrival indicator for 2023...\n",
      "Identified 32447 late-night arrivals (22:00-06:00)\n",
      "Total identified late-night arrivals: 32447 out of 219176 total flights (14.80%)\n",
      "\n",
      "Distribution of flights by arrival time of day:\n",
      "  - Afternoon (12-18): 73902 flights (33.72%)\n",
      "  - Morning (6-12): 60496 flights (27.60%)\n",
      "  - Evening (18-22): 53063 flights (24.21%)\n",
      "  - Night (22-24): 22725 flights (10.37%)\n",
      "  - Early Morning (0-6): 8990 flights (4.10%)\n",
      "\n",
      "Preparing arrival delay data for 2023...\n",
      "\n",
      "Arrival delay statistics:\n",
      "Delayed arrivals: 78790/219176 (35.95%)\n",
      "On-time or early arrivals: 140386/219176 (64.05%)\n",
      "\n",
      "Arrival delay magnitude statistics:\n",
      "Mean arrival delay: 5.21 minutes\n",
      "Median arrival delay: -6.00 minutes\n",
      "Min arrival delay: -84.00 minutes (negative means early arrival)\n",
      "Max arrival delay: 3237.00 minutes\n",
      "\n",
      "Arrival delay category distribution:\n",
      "  - Very Early: 61806 flights (28.20%)\n",
      "  - Early: 78059 flights (35.61%)\n",
      "  - On Time: 36197 flights (16.52%)\n",
      "  - Slight Delay: 15482 flights (7.06%)\n",
      "  - Moderate Delay: 13160 flights (6.00%)\n",
      "  - Significant Delay: 8629 flights (3.94%)\n",
      "  - Severe Delay: 5322 flights (2.43%)\n",
      "\n",
      "Flights with arrival delay worse than departure delay: 50024/219176 (22.82%)\n",
      "\n",
      "Creating arrival time block features for 2023...\n",
      "\n",
      "Creating day features for 2023...\n",
      "\n",
      "Distribution of flights by day of week:\n",
      "  - Monday: 36506 flights (16.66%)\n",
      "  - Wednesday: 35633 flights (16.26%)\n",
      "  - Tuesday: 35382 flights (16.14%)\n",
      "  - Thursday: 29268 flights (13.35%)\n",
      "  - Friday: 29138 flights (13.29%)\n",
      "  - Sunday: 28009 flights (12.78%)\n",
      "  - Saturday: 25240 flights (11.52%)\n",
      "\n",
      "Weekend flights: 53249 (24.30%)\n",
      "Weekday flights: 165927 (75.70%)\n",
      "\n",
      "Creating flight duration features for 2023...\n",
      "\n",
      "Flight duration statistics:\n",
      "Mean scheduled duration: 191.3 minutes\n",
      "Mean actual duration: 188.4 minutes\n",
      "Mean duration difference: -2.9 minutes\n",
      "Flights faster than scheduled: 131818 (60.1%)\n",
      "Flights slower than scheduled: 83236 (38.0%)\n",
      "\n",
      "Flight duration deviation distribution:\n",
      "  - Much Faster: 65758 flights (30.00%)\n",
      "  - Faster: 47736 flights (21.78%)\n",
      "  - On Schedule: 37285 flights (17.01%)\n",
      "  - Slower: 15269 flights (6.97%)\n",
      "  - Much Slower: 25608 flights (11.68%)\n",
      "  - Extremely Slower: 27492 flights (12.54%)\n",
      "\n",
      "Flight distance distribution:\n",
      "  - Very Short (<300 mi): 19188 flights (8.75%)\n",
      "  - Short (300-600 mi): 39527 flights (18.03%)\n",
      "  - Medium (600-1000 mi): 67896 flights (30.98%)\n",
      "  - Long (1000-1500 mi): 44389 flights (20.25%)\n",
      "  - Very Long (>1500 mi): 48176 flights (21.98%)\n",
      "\n",
      "Selecting features for arrival delay prediction for 2023...\n",
      "Using categorical features: ['DAY_NAME', 'ARR_TIME_BLOCK', 'MKT_AIRLINE', 'ORIGIN_IATA', 'DEST_IATA', 'FLIGHT_DISTANCE_CAT', 'DURATION_DEVIATION', 'IS_LATE_NIGHT_ARR', 'IS_WEEKEND', 'IS_MORNING_RUSH_ARR', 'IS_EVENING_RUSH_ARR', 'EXTREME_WEATHER', 'DEST_EXTREME_WEATHER']\n",
      "Using numerical features: ['DISTANCE', 'SCH_DURATION_MINS', 'PRCP', 'DEST_PRCP', 'DEP_DELAY']\n",
      "Warning: Found 521 NaN values in ARR_DELAY. Removing these records.\n",
      "After removing NaN values, remaining records: 218655\n",
      "Training set size: (163991, 18)\n",
      "Test set size: (54664, 18)\n",
      "\n",
      "Training arrival delay classification model for 2023 (Random Forest)...\n",
      "Arrival delay classification model training took: 42.25 seconds\n",
      "\n",
      "Training arrival delay regression model for 2023 (Random Forest)...\n",
      "Arrival delay regression model training took: 498.87 seconds\n",
      "\n",
      "Evaluating arrival delay classification model for 2023...\n",
      "Arrival Delay Classification Accuracy: 89.06%\n",
      "Arrival Delay Classification ROC AUC: 0.9560\n",
      "Arrival Delay Classification Precision (Delayed): 0.8440\n",
      "Arrival Delay Classification Recall (Delayed): 0.8542\n",
      "Arrival Delay Classification F1 Score (Delayed): 0.8491\n",
      "\n",
      "Evaluating arrival delay regression model for 2023...\n",
      "Arrival Delay Regression Mean Squared Error: 157.82\n",
      "Arrival Delay Regression Root Mean Squared Error: 12.56 minutes\n",
      "Arrival Delay Regression Mean Absolute Error: 6.51 minutes\n",
      "Arrival Delay Regression R² Score: 0.9457\n",
      "Feature importance plot saved to ./rf_arrival_delay_models/year_2023\\plots\\arrival_delay_class_feature_importance_2023.png\n",
      "\n",
      "Top 10 most important features for arrival delay classification in 2023:\n",
      "                                     Feature  Importance\n",
      "4                             num__DEP_DELAY    0.586646\n",
      "99            cat__DURATION_DEVIATION_Slower    0.058507\n",
      "95            cat__DURATION_DEVIATION_Faster    0.037015\n",
      "94  cat__DURATION_DEVIATION_Extremely Slower    0.033497\n",
      "96       cat__DURATION_DEVIATION_Much Faster    0.025773\n",
      "1                     num__SCH_DURATION_MINS    0.023684\n",
      "0                              num__DISTANCE    0.020983\n",
      "98       cat__DURATION_DEVIATION_On Schedule    0.015754\n",
      "3                             num__DEST_PRCP    0.008877\n",
      "17        cat__ARR_TIME_BLOCK_Mid-Day (9-12)    0.008076\n",
      "\n",
      "Day of week feature importance for arrival delay classification in 2023:\n",
      "                    Feature  Importance\n",
      "10    cat__DAY_NAME_Tuesday    0.001946\n",
      "9    cat__DAY_NAME_Thursday    0.001708\n",
      "6      cat__DAY_NAME_Monday    0.001703\n",
      "5      cat__DAY_NAME_Friday    0.001670\n",
      "11  cat__DAY_NAME_Wednesday    0.001588\n",
      "7    cat__DAY_NAME_Saturday    0.001328\n",
      "8      cat__DAY_NAME_Sunday    0.001207\n",
      "Feature importance plot saved to ./rf_arrival_delay_models/year_2023\\plots\\arrival_delay_reg_feature_importance_2023.png\n",
      "\n",
      "Top 10 most important features for arrival delay regression in 2023:\n",
      "                                     Feature  Importance\n",
      "4                             num__DEP_DELAY    0.952647\n",
      "96       cat__DURATION_DEVIATION_Much Faster    0.009097\n",
      "94  cat__DURATION_DEVIATION_Extremely Slower    0.007076\n",
      "1                     num__SCH_DURATION_MINS    0.006948\n",
      "0                              num__DISTANCE    0.005568\n",
      "3                             num__DEST_PRCP    0.001833\n",
      "98       cat__DURATION_DEVIATION_On Schedule    0.001747\n",
      "43                      cat__ORIGIN_IATA_JFK    0.001452\n",
      "99            cat__DURATION_DEVIATION_Slower    0.001425\n",
      "2                                  num__PRCP    0.000884\n",
      "\n",
      "Day of week feature importance for arrival delay regression in 2023:\n",
      "                    Feature  Importance\n",
      "11  cat__DAY_NAME_Wednesday    0.000233\n",
      "9    cat__DAY_NAME_Thursday    0.000155\n",
      "6      cat__DAY_NAME_Monday    0.000154\n",
      "10    cat__DAY_NAME_Tuesday    0.000152\n",
      "5      cat__DAY_NAME_Friday    0.000138\n",
      "8      cat__DAY_NAME_Sunday    0.000099\n",
      "7    cat__DAY_NAME_Saturday    0.000098\n",
      "Models saved to ./rf_arrival_delay_models/year_2023\n",
      "\n",
      "Arrival delay model training for 2023 complete! Total processing time: 708.72 seconds\n",
      "\n",
      "Arrival delay model for year 2023 completed successfully!\n",
      "\n",
      "================================================================================\n",
      "Training Arrival Delay model for year 2024\n",
      "================================================================================\n",
      "\n",
      "Processing May2024.csv...\n",
      "Years found in data: [2024]\n",
      "Months found in data: {5: 649428}\n",
      "Filtered to only May data: 649428 rows\n",
      "Filtered from 649428 to 228159 rows for top 30 airports\n",
      "Removed 2994.0 cancelled flights, remaining: 225165\n",
      "Processing took: 4.92 seconds\n",
      "\n",
      "Matching origin weather data with flights...\n",
      "Processed 10000/225165 rows, matched 7108 flights with origin weather data\n",
      "Processed 20000/225165 rows, matched 14410 flights with origin weather data\n",
      "Processed 30000/225165 rows, matched 21856 flights with origin weather data\n",
      "Processed 40000/225165 rows, matched 29104 flights with origin weather data\n",
      "Processed 50000/225165 rows, matched 36479 flights with origin weather data\n",
      "Processed 60000/225165 rows, matched 43708 flights with origin weather data\n",
      "Processed 70000/225165 rows, matched 50965 flights with origin weather data\n",
      "Processed 80000/225165 rows, matched 58539 flights with origin weather data\n",
      "Processed 90000/225165 rows, matched 65682 flights with origin weather data\n",
      "Processed 100000/225165 rows, matched 73009 flights with origin weather data\n",
      "Processed 110000/225165 rows, matched 80433 flights with origin weather data\n",
      "Processed 120000/225165 rows, matched 87679 flights with origin weather data\n",
      "Processed 130000/225165 rows, matched 95122 flights with origin weather data\n",
      "Processed 140000/225165 rows, matched 102419 flights with origin weather data\n",
      "Processed 150000/225165 rows, matched 109622 flights with origin weather data\n",
      "Processed 160000/225165 rows, matched 117118 flights with origin weather data\n",
      "Processed 170000/225165 rows, matched 124380 flights with origin weather data\n",
      "Processed 180000/225165 rows, matched 131691 flights with origin weather data\n",
      "Processed 190000/225165 rows, matched 139073 flights with origin weather data\n",
      "Processed 200000/225165 rows, matched 146378 flights with origin weather data\n",
      "Processed 210000/225165 rows, matched 153882 flights with origin weather data\n",
      "Processed 220000/225165 rows, matched 161154 flights with origin weather data\n",
      "Processed 225165/225165 rows, matched 165140 flights with origin weather data\n",
      "Matched origin weather data for 165140 flights (73.34%)\n",
      "Origin weather matching took: 82.87 seconds\n",
      "\n",
      "Matching destination weather data with flights...\n",
      "Processed 10000/225165 rows, matched 7121 flights with destination weather data\n",
      "Processed 20000/225165 rows, matched 14417 flights with destination weather data\n",
      "Processed 30000/225165 rows, matched 21861 flights with destination weather data\n",
      "Processed 40000/225165 rows, matched 29117 flights with destination weather data\n",
      "Processed 50000/225165 rows, matched 36461 flights with destination weather data\n",
      "Processed 60000/225165 rows, matched 43702 flights with destination weather data\n",
      "Processed 70000/225165 rows, matched 50955 flights with destination weather data\n",
      "Processed 80000/225165 rows, matched 58538 flights with destination weather data\n",
      "Processed 90000/225165 rows, matched 65680 flights with destination weather data\n",
      "Processed 100000/225165 rows, matched 73000 flights with destination weather data\n",
      "Processed 110000/225165 rows, matched 80446 flights with destination weather data\n",
      "Processed 120000/225165 rows, matched 87677 flights with destination weather data\n",
      "Processed 130000/225165 rows, matched 95115 flights with destination weather data\n",
      "Processed 140000/225165 rows, matched 102411 flights with destination weather data\n",
      "Processed 150000/225165 rows, matched 109627 flights with destination weather data\n",
      "Processed 160000/225165 rows, matched 117106 flights with destination weather data\n",
      "Processed 170000/225165 rows, matched 124377 flights with destination weather data\n",
      "Processed 180000/225165 rows, matched 131707 flights with destination weather data\n",
      "Processed 190000/225165 rows, matched 139063 flights with destination weather data\n",
      "Processed 200000/225165 rows, matched 146367 flights with destination weather data\n",
      "Processed 210000/225165 rows, matched 153874 flights with destination weather data\n",
      "Processed 220000/225165 rows, matched 161153 flights with destination weather data\n",
      "Processed 225165/225165 rows, matched 165138 flights with destination weather data\n",
      "Matched destination weather data for 165138 flights (73.34%)\n",
      "Destination weather matching took: 81.75 seconds\n",
      "\n",
      "Analyzing correlation between departure and arrival delays...\n",
      "Correlation between departure and arrival delays: 0.9695\n",
      "Mean difference (ARR_DELAY - DEP_DELAY): -4.16 minutes\n",
      "Median difference: -7.00 minutes\n",
      "Flights where arrival delay > departure delay: 64090 (28.5%)\n",
      "Flights where arrival delay < departure delay: 154679 (68.7%)\n",
      "\n",
      "Creating late-night arrival indicator for 2024...\n",
      "Identified 32833 late-night arrivals (22:00-06:00)\n",
      "Total identified late-night arrivals: 32833 out of 225165 total flights (14.58%)\n",
      "\n",
      "Distribution of flights by arrival time of day:\n",
      "  - Afternoon (12-18): 75900 flights (33.71%)\n",
      "  - Morning (6-12): 61953 flights (27.51%)\n",
      "  - Evening (18-22): 55276 flights (24.55%)\n",
      "  - Night (22-24): 23606 flights (10.48%)\n",
      "  - Early Morning (0-6): 8430 flights (3.74%)\n",
      "\n",
      "Preparing arrival delay data for 2024...\n",
      "\n",
      "Arrival delay statistics:\n",
      "Delayed arrivals: 102530/225165 (45.54%)\n",
      "On-time or early arrivals: 122635/225165 (54.46%)\n",
      "\n",
      "Arrival delay magnitude statistics:\n",
      "Mean arrival delay: 16.32 minutes\n",
      "Median arrival delay: -2.00 minutes\n",
      "Min arrival delay: -69.00 minutes (negative means early arrival)\n",
      "Max arrival delay: 2236.00 minutes\n",
      "\n",
      "Arrival delay category distribution:\n",
      "  - Very Early: 49461 flights (21.97%)\n",
      "  - Early: 72210 flights (32.07%)\n",
      "  - On Time: 38807 flights (17.23%)\n",
      "  - Slight Delay: 19093 flights (8.48%)\n",
      "  - Moderate Delay: 19018 flights (8.45%)\n",
      "  - Significant Delay: 14713 flights (6.53%)\n",
      "  - Severe Delay: 10899 flights (4.84%)\n",
      "\n",
      "Flights with arrival delay worse than departure delay: 64090/225165 (28.46%)\n",
      "\n",
      "Creating arrival time block features for 2024...\n",
      "\n",
      "Creating day features for 2024...\n",
      "\n",
      "Distribution of flights by day of week:\n",
      "  - Friday: 37632 flights (16.71%)\n",
      "  - Thursday: 37381 flights (16.60%)\n",
      "  - Wednesday: 36037 flights (16.00%)\n",
      "  - Monday: 30205 flights (13.41%)\n",
      "  - Sunday: 28931 flights (12.85%)\n",
      "  - Tuesday: 28826 flights (12.80%)\n",
      "  - Saturday: 26153 flights (11.62%)\n",
      "\n",
      "Weekend flights: 55084 (24.46%)\n",
      "Weekday flights: 170081 (75.54%)\n",
      "\n",
      "Creating flight duration features for 2024...\n",
      "\n",
      "Flight duration statistics:\n",
      "Mean scheduled duration: 191.8 minutes\n",
      "Mean actual duration: 191.8 minutes\n",
      "Mean duration difference: -0.0 minutes\n",
      "Flights faster than scheduled: 126781 (56.3%)\n",
      "Flights slower than scheduled: 94186 (41.8%)\n",
      "\n",
      "Flight duration deviation distribution:\n",
      "  - Much Faster: 62008 flights (27.54%)\n",
      "  - Faster: 45987 flights (20.42%)\n",
      "  - On Schedule: 38973 flights (17.31%)\n",
      "  - Slower: 16834 flights (7.48%)\n",
      "  - Much Slower: 26963 flights (11.97%)\n",
      "  - Extremely Slower: 34360 flights (15.26%)\n",
      "\n",
      "Flight distance distribution:\n",
      "  - Very Short (<300 mi): 18713 flights (8.31%)\n",
      "  - Short (300-600 mi): 40408 flights (17.95%)\n",
      "  - Medium (600-1000 mi): 70725 flights (31.41%)\n",
      "  - Long (1000-1500 mi): 45248 flights (20.10%)\n",
      "  - Very Long (>1500 mi): 50071 flights (22.24%)\n",
      "\n",
      "Selecting features for arrival delay prediction for 2024...\n",
      "Using categorical features: ['DAY_NAME', 'ARR_TIME_BLOCK', 'MKT_AIRLINE', 'ORIGIN_IATA', 'DEST_IATA', 'FLIGHT_DISTANCE_CAT', 'DURATION_DEVIATION', 'IS_LATE_NIGHT_ARR', 'IS_WEEKEND', 'IS_MORNING_RUSH_ARR', 'IS_EVENING_RUSH_ARR', 'EXTREME_WEATHER', 'DEST_EXTREME_WEATHER']\n",
      "Using numerical features: ['DISTANCE', 'SCH_DURATION_MINS', 'PRCP', 'DEST_PRCP', 'DEP_DELAY']\n",
      "Warning: Found 964 NaN values in ARR_DELAY. Removing these records.\n",
      "After removing NaN values, remaining records: 224201\n",
      "Training set size: (168150, 18)\n",
      "Test set size: (56051, 18)\n",
      "\n",
      "Training arrival delay classification model for 2024 (Random Forest)...\n",
      "Arrival delay classification model training took: 44.17 seconds\n",
      "\n",
      "Training arrival delay regression model for 2024 (Random Forest)...\n",
      "Arrival delay regression model training took: 568.00 seconds\n",
      "\n",
      "Evaluating arrival delay classification model for 2024...\n",
      "Arrival Delay Classification Accuracy: 88.80%\n",
      "Arrival Delay Classification ROC AUC: 0.9543\n",
      "Arrival Delay Classification Precision (Delayed): 0.8973\n",
      "Arrival Delay Classification Recall (Delayed): 0.8528\n",
      "Arrival Delay Classification F1 Score (Delayed): 0.8745\n",
      "\n",
      "Evaluating arrival delay regression model for 2024...\n",
      "Arrival Delay Regression Mean Squared Error: 161.03\n",
      "Arrival Delay Regression Root Mean Squared Error: 12.69 minutes\n",
      "Arrival Delay Regression Mean Absolute Error: 7.82 minutes\n",
      "Arrival Delay Regression R² Score: 0.9653\n",
      "Feature importance plot saved to ./rf_arrival_delay_models/year_2024\\plots\\arrival_delay_class_feature_importance_2024.png\n",
      "\n",
      "Top 10 most important features for arrival delay classification in 2024:\n",
      "                                     Feature  Importance\n",
      "4                             num__DEP_DELAY    0.611827\n",
      "99            cat__DURATION_DEVIATION_Slower    0.059634\n",
      "94  cat__DURATION_DEVIATION_Extremely Slower    0.038008\n",
      "95            cat__DURATION_DEVIATION_Faster    0.036207\n",
      "96       cat__DURATION_DEVIATION_Much Faster    0.021617\n",
      "1                     num__SCH_DURATION_MINS    0.020908\n",
      "0                              num__DISTANCE    0.017198\n",
      "98       cat__DURATION_DEVIATION_On Schedule    0.013932\n",
      "18         cat__ARR_TIME_BLOCK_Morning (6-9)    0.011090\n",
      "2                                  num__PRCP    0.010464\n",
      "\n",
      "Day of week feature importance for arrival delay classification in 2024:\n",
      "                    Feature  Importance\n",
      "7    cat__DAY_NAME_Saturday    0.001858\n",
      "9    cat__DAY_NAME_Thursday    0.001726\n",
      "5      cat__DAY_NAME_Friday    0.001533\n",
      "11  cat__DAY_NAME_Wednesday    0.001398\n",
      "10    cat__DAY_NAME_Tuesday    0.001278\n",
      "6      cat__DAY_NAME_Monday    0.001238\n",
      "8      cat__DAY_NAME_Sunday    0.001176\n",
      "Feature importance plot saved to ./rf_arrival_delay_models/year_2024\\plots\\arrival_delay_reg_feature_importance_2024.png\n",
      "\n",
      "Top 10 most important features for arrival delay regression in 2024:\n",
      "                                     Feature  Importance\n",
      "4                             num__DEP_DELAY    0.963146\n",
      "94  cat__DURATION_DEVIATION_Extremely Slower    0.010520\n",
      "1                     num__SCH_DURATION_MINS    0.004436\n",
      "96       cat__DURATION_DEVIATION_Much Faster    0.003446\n",
      "0                              num__DISTANCE    0.003199\n",
      "3                             num__DEST_PRCP    0.001967\n",
      "2                                  num__PRCP    0.001192\n",
      "95            cat__DURATION_DEVIATION_Faster    0.000984\n",
      "99            cat__DURATION_DEVIATION_Slower    0.000924\n",
      "98       cat__DURATION_DEVIATION_On Schedule    0.000744\n",
      "\n",
      "Day of week feature importance for arrival delay regression in 2024:\n",
      "                    Feature  Importance\n",
      "11  cat__DAY_NAME_Wednesday    0.000221\n",
      "9    cat__DAY_NAME_Thursday    0.000199\n",
      "6      cat__DAY_NAME_Monday    0.000145\n",
      "5      cat__DAY_NAME_Friday    0.000140\n",
      "10    cat__DAY_NAME_Tuesday    0.000127\n",
      "8      cat__DAY_NAME_Sunday    0.000116\n",
      "7    cat__DAY_NAME_Saturday    0.000072\n",
      "Models saved to ./rf_arrival_delay_models/year_2024\n",
      "\n",
      "Arrival delay model training for 2024 complete! Total processing time: 787.16 seconds\n",
      "\n",
      "Arrival delay model for year 2024 completed successfully!\n",
      "\n",
      "Comparing arrival delay models across years...\n",
      "Comparison summary saved to ./rf_arrival_delay_models/comparison\\arrival_delay_model_comparison.csv\n",
      "Arrival delay model comparison completed!\n",
      "\n",
      "Year-by-Year Arrival Delay Model Training Summary:\n",
      "\n",
      "Year 2021:\n",
      "  Total flights: 170,900\n",
      "  Arrival delay classification accuracy: 88.48%\n",
      "  Arrival delay classification AUC: 0.9477\n",
      "  Arrival delay regression RMSE: 10.28 minutes\n",
      "  Arrival delay regression R²: 0.9386\n",
      "  Mean arrival delay: -1.71 minutes\n",
      "  Arrival delay rate: 27.19%\n",
      "  Departure-arrival delay correlation: 0.9462\n",
      "  Top 3 features for arrival delay classification:\n",
      "    1. num__DEP_DELAY: 0.5620\n",
      "    2. cat__DURATION_DEVIATION_Slower: 0.0696\n",
      "    3. cat__DURATION_DEVIATION_Faster: 0.0401\n",
      "\n",
      "Year 2022:\n",
      "  Total flights: 205,420\n",
      "  Arrival delay classification accuracy: 88.16%\n",
      "  Arrival delay classification AUC: 0.9505\n",
      "  Arrival delay regression RMSE: 11.83 minutes\n",
      "  Arrival delay regression R²: 0.9560\n",
      "  Mean arrival delay: 8.59 minutes\n",
      "  Arrival delay rate: 40.40%\n",
      "  Departure-arrival delay correlation: 0.9608\n",
      "  Top 3 features for arrival delay classification:\n",
      "    1. num__DEP_DELAY: 0.6044\n",
      "    2. cat__DURATION_DEVIATION_Slower: 0.0624\n",
      "    3. cat__DURATION_DEVIATION_Faster: 0.0414\n",
      "\n",
      "Year 2023:\n",
      "  Total flights: 219,176\n",
      "  Arrival delay classification accuracy: 89.06%\n",
      "  Arrival delay classification AUC: 0.9560\n",
      "  Arrival delay regression RMSE: 12.56 minutes\n",
      "  Arrival delay regression R²: 0.9457\n",
      "  Mean arrival delay: 5.21 minutes\n",
      "  Arrival delay rate: 35.95%\n",
      "  Departure-arrival delay correlation: 0.9633\n",
      "  Top 3 features for arrival delay classification:\n",
      "    1. num__DEP_DELAY: 0.5866\n",
      "    2. cat__DURATION_DEVIATION_Slower: 0.0585\n",
      "    3. cat__DURATION_DEVIATION_Faster: 0.0370\n",
      "\n",
      "Year 2024:\n",
      "  Total flights: 225,165\n",
      "  Arrival delay classification accuracy: 88.80%\n",
      "  Arrival delay classification AUC: 0.9543\n",
      "  Arrival delay regression RMSE: 12.69 minutes\n",
      "  Arrival delay regression R²: 0.9653\n",
      "  Mean arrival delay: 16.32 minutes\n",
      "  Arrival delay rate: 45.54%\n",
      "  Departure-arrival delay correlation: 0.9695\n",
      "  Top 3 features for arrival delay classification:\n",
      "    1. num__DEP_DELAY: 0.6118\n",
      "    2. cat__DURATION_DEVIATION_Slower: 0.0596\n",
      "    3. cat__DURATION_DEVIATION_Extremely Slower: 0.0380\n",
      "\n",
      "Training complete! Check output directories for detailed results.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main execution\n",
    "all_results = []\n",
    "\n",
    "# Process each year's file separately\n",
    "for file_path in flight_files:\n",
    "    year = extract_year_from_filename(file_path)\n",
    "    results = train_year_model(year, file_path)\n",
    "    \n",
    "    if results:\n",
    "        all_results.append(results)\n",
    "        print(f\"\\nArrival delay model for year {year} completed successfully!\")\n",
    "    else:\n",
    "        print(f\"\\nArrival delay model for year {year} failed.\")\n",
    "\n",
    "# After all individual models are trained, compare them\n",
    "if len(all_results) > 1:\n",
    "    compare_year_models(all_results)\n",
    "else:\n",
    "    print(\"\\nNot enough successful models to perform comparison.\")\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\nYear-by-Year Arrival Delay Model Training Summary:\")\n",
    "for year_result in all_results:\n",
    "    year = year_result['year']\n",
    "    print(f\"\\nYear {year}:\")\n",
    "    print(f\"  Total flights: {year_result['total_flights']:,}\")\n",
    "    print(f\"  Arrival delay classification accuracy: {year_result['class_accuracy']:.2f}%\")\n",
    "    print(f\"  Arrival delay classification AUC: {year_result['class_roc_auc']:.4f}\")\n",
    "    print(f\"  Arrival delay regression RMSE: {year_result['reg_rmse']:.2f} minutes\")\n",
    "    print(f\"  Arrival delay regression R²: {year_result['reg_r2']:.4f}\")\n",
    "    print(f\"  Mean arrival delay: {year_result['mean_arr_delay']:.2f} minutes\")\n",
    "    print(f\"  Arrival delay rate: {year_result['arr_delayed_flights_rate']:.2f}%\")\n",
    "    \n",
    "    if 'dep_arr_delay_correlation' in year_result and year_result['dep_arr_delay_correlation'] is not None:\n",
    "        print(f\"  Departure-arrival delay correlation: {year_result['dep_arr_delay_correlation']:.4f}\")\n",
    "    \n",
    "    # Print top 3 features for arrival delay classification\n",
    "    print(f\"  Top 3 features for arrival delay classification:\")\n",
    "    for i in range(1, 4):\n",
    "        feature_key = f'class_top_feature_{i}'\n",
    "        importance_key = f'class_top_feature_{i}_importance'\n",
    "        if feature_key in year_result and importance_key in year_result:\n",
    "            print(f\"    {i}. {year_result[feature_key]}: {year_result[importance_key]:.4f}\")\n",
    "\n",
    "print(\"\\nTraining complete! Check output directories for detailed results.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
