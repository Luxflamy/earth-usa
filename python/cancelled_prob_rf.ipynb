{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T19:56:26.733328Z",
     "start_time": "2025-04-17T19:56:26.727398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting flight cancellation prediction models with red-eye flight detection (Random Forest)...\n",
      "Flight data directory: ./cleaned_data/\n",
      "Weather data directory: ./cleaned_weather_data/\n",
      "Top airports file: ./top_100_airports.csv\n",
      "Model output directory: ./cancelled_prob_rf_models/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import dump\n",
    "\n",
    "# Set data paths\n",
    "flight_data_path = './cleaned_data/'\n",
    "weather_data_path = './cleaned_weather_data/'\n",
    "top_airports_file = './top_100_airports.csv' \n",
    "output_dir = './cancelled_prob_rf_models/'  \n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'metrics'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'plots'), exist_ok=True)\n",
    "\n",
    "print(\"Starting flight cancellation prediction models with red-eye flight detection (Random Forest)...\")\n",
    "print(f\"Flight data directory: {flight_data_path}\")\n",
    "print(f\"Weather data directory: {weather_data_path}\")\n",
    "print(f\"Top airports file: {top_airports_file}\")\n",
    "print(f\"Model output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T19:56:26.748334Z",
     "start_time": "2025-04-17T19:56:26.740334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded top 30 airports: ATL, AUS, BNA, BOS, BWI, CLT, DCA, DEN, DFW, DTW, EWR, FLL, IAD, IAH, JFK, LAS, LAX, LGA, MCO, MDW, MIA, MSP, ORD, PHL, PHX, SAN, SEA, SFO, SLC, TPA\n",
      "Busiest airport: ATL with 457121 flights\n",
      "30th busiest airport: TPA with 97235 flights\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load top 30 airports from the top 100 airports file\n",
    "try:\n",
    "    # Load the airport data with the exact format provided\n",
    "    top_airports = pd.read_csv(top_airports_file, low_memory=False)\n",
    "    \n",
    "    # The file already has a Rank column, so we can just take the top 30\n",
    "    top_airports = top_airports.head(30)\n",
    "    \n",
    "    # The airport codes are in ORIGIN_IATA column\n",
    "    top_airport_codes = set(top_airports['ORIGIN_IATA'].str.strip().tolist())\n",
    "    \n",
    "    print(f\"Loaded top 30 airports: {', '.join(sorted(top_airport_codes))}\")\n",
    "    print(f\"Busiest airport: {top_airports.iloc[0]['ORIGIN_IATA']} with {top_airports.iloc[0]['Times']} flights\")\n",
    "    print(f\"30th busiest airport: {top_airports.iloc[29]['ORIGIN_IATA']} with {top_airports.iloc[29]['Times']} flights\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading top airports file: {e}\")\n",
    "    # Fallback: if file doesn't exist, we'll use all airports\n",
    "    top_airport_codes = None\n",
    "    print(\"Will process all airports (top airports file not available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T19:56:26.793344Z",
     "start_time": "2025-04-17T19:56:26.786036Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to load weather data for top airports only - specifically for May 2021-2024\n",
    "def load_weather_data():\n",
    "    print(\"\\nLoading weather data for May 2021-2024...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    all_files = glob.glob(os.path.join(weather_data_path, \"*.csv\"))\n",
    "    print(f\"Found {len(all_files)} total weather data files\")\n",
    "    weather_dict = {}\n",
    "    count = 0\n",
    "    matching_count = 0\n",
    "    \n",
    "    # Define target years and month\n",
    "    target_years = ['2021', '2022', '2023', '2024']\n",
    "    target_month = 'May'\n",
    "    \n",
    "    for file in all_files:\n",
    "        try:\n",
    "            # Extract IATA code from filename\n",
    "            filename = os.path.basename(file)\n",
    "            parts = filename.split('.')[0].split('_')\n",
    "            \n",
    "            if len(parts) >= 3:\n",
    "                iata = parts[0]\n",
    "                year = parts[1]\n",
    "                month = parts[2]\n",
    "                \n",
    "                # Only load weather data for May 2021-2024 and top airports\n",
    "                if (year in target_years and \n",
    "                    month == target_month and\n",
    "                    (top_airport_codes is None or iata in top_airport_codes)):\n",
    "                    \n",
    "                    key = f\"{iata}_{year}_{month}\"\n",
    "                    \n",
    "                    # Add low_memory=False to handle mixed types warning\n",
    "                    weather_dict[key] = pd.read_csv(file, low_memory=False)\n",
    "                    matching_count += 1\n",
    "                \n",
    "                count += 1\n",
    "                    \n",
    "                # Print progress periodically\n",
    "                if count % 100 == 0:\n",
    "                    print(f\"Processed {count} weather files, loaded {matching_count} matching files\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading weather file {file}: {e}\")\n",
    "    \n",
    "    print(f\"Loaded {matching_count} weather files for May 2021-2024 out of {count} processed files\")\n",
    "    print(f\"Loading weather data took: {time.time() - start_time:.2f} seconds\")\n",
    "    return weather_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T19:56:26.892350Z",
     "start_time": "2025-04-17T19:56:26.797349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 4 May files to process:\n",
      "  - May2021.csv\n",
      "  - May2022.csv\n",
      "  - May2023.csv\n",
      "  - May2024.csv\n",
      "\n",
      "Loading weather data for May 2021-2024...\n",
      "Found 3550 total weather data files\n",
      "Processed 100 weather files, loaded 0 matching files\n",
      "Processed 200 weather files, loaded 0 matching files\n",
      "Processed 300 weather files, loaded 4 matching files\n",
      "Processed 400 weather files, loaded 8 matching files\n",
      "Processed 500 weather files, loaded 8 matching files\n",
      "Processed 600 weather files, loaded 12 matching files\n",
      "Processed 700 weather files, loaded 12 matching files\n",
      "Processed 800 weather files, loaded 12 matching files\n",
      "Processed 900 weather files, loaded 16 matching files\n",
      "Processed 1000 weather files, loaded 16 matching files\n",
      "Processed 1100 weather files, loaded 20 matching files\n",
      "Processed 1200 weather files, loaded 24 matching files\n",
      "Processed 1300 weather files, loaded 28 matching files\n",
      "Processed 1400 weather files, loaded 28 matching files\n",
      "Processed 1500 weather files, loaded 28 matching files\n",
      "Processed 1600 weather files, loaded 28 matching files\n",
      "Processed 1700 weather files, loaded 32 matching files\n",
      "Processed 1800 weather files, loaded 32 matching files\n",
      "Processed 1900 weather files, loaded 35 matching files\n",
      "Processed 2000 weather files, loaded 40 matching files\n",
      "Processed 2100 weather files, loaded 40 matching files\n",
      "Processed 2200 weather files, loaded 48 matching files\n",
      "Processed 2300 weather files, loaded 52 matching files\n",
      "Processed 2400 weather files, loaded 52 matching files\n",
      "Processed 2500 weather files, loaded 56 matching files\n",
      "Processed 2600 weather files, loaded 60 matching files\n",
      "Processed 2700 weather files, loaded 60 matching files\n",
      "Processed 2800 weather files, loaded 64 matching files\n",
      "Processed 2900 weather files, loaded 64 matching files\n",
      "Processed 3000 weather files, loaded 68 matching files\n",
      "Processed 3100 weather files, loaded 71 matching files\n",
      "Processed 3200 weather files, loaded 76 matching files\n",
      "Processed 3300 weather files, loaded 80 matching files\n",
      "Processed 3400 weather files, loaded 84 matching files\n",
      "Processed 3500 weather files, loaded 84 matching files\n",
      "Loaded 84 weather files for May 2021-2024 out of 3550 processed files\n",
      "Loading weather data took: 0.08 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get specific May files from the cleaned_data directory based on the file list you shared\n",
    "def get_may_files():\n",
    "    may_files = [\n",
    "        os.path.join(flight_data_path, \"May2021.csv\"),\n",
    "        os.path.join(flight_data_path, \"May2022.csv\"),\n",
    "        os.path.join(flight_data_path, \"May2023.csv\"),\n",
    "        os.path.join(flight_data_path, \"May2024.csv\")\n",
    "    ]\n",
    "    \n",
    "    # Verify each file exists\n",
    "    existing_files = []\n",
    "    for file_path in may_files:\n",
    "        if os.path.exists(file_path):\n",
    "            existing_files.append(file_path)\n",
    "        else:\n",
    "            print(f\"Warning: File {file_path} not found\")\n",
    "    \n",
    "    return existing_files\n",
    "\n",
    "# Get the May 2021-2024 flight data files\n",
    "flight_files = get_may_files()\n",
    "print(f\"\\nFound {len(flight_files)} May files to process:\")\n",
    "for f in flight_files:\n",
    "    print(f\"  - {os.path.basename(f)}\")\n",
    "\n",
    "if not flight_files:\n",
    "    print(\"No May 2021-2024 files were found. Please check file paths.\")\n",
    "    exit(1)\n",
    "\n",
    "# Load all weather data once (shared across all models)\n",
    "weather_dict = load_weather_data()\n",
    "\n",
    "# Function to extract year from filename (for logging purposes only)\n",
    "def extract_year_from_filename(filename):\n",
    "    base_name = os.path.basename(filename)\n",
    "    year_str = base_name.replace('May', '').split('.')[0]\n",
    "    return int(year_str)\n",
    "\n",
    "# Function to create red-eye flight indicator\n",
    "def create_redeye_indicator(df):\n",
    "    \"\"\"\n",
    "    Creates a binary indicator for red-eye flights (0-6 AM departure or arrival)\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing flight data with departure and arrival times\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with IS_REDEYE column added\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Initialize IS_REDEYE to 0 (not a red-eye flight)\n",
    "    df['IS_REDEYE'] = 0\n",
    "    \n",
    "    # Check for departure time columns\n",
    "    dep_time_cols = [col for col in df.columns if 'DEP_TIME' in col.upper()]\n",
    "    \n",
    "    # Check for arrival time columns\n",
    "    arr_time_cols = [col for col in df.columns if 'ARR_TIME' in col.upper()]\n",
    "    \n",
    "    # If we have departure time\n",
    "    if dep_time_cols:\n",
    "        dep_time_col = dep_time_cols[0]  # Use the first one found\n",
    "        \n",
    "        # Convert to float if it's not already\n",
    "        if df[dep_time_col].dtype != 'float64':\n",
    "            try:\n",
    "                df[dep_time_col] = df[dep_time_col].astype(float)\n",
    "            except:\n",
    "                # Handle any errors in conversion\n",
    "                print(f\"Warning: Could not convert {dep_time_col} to float\")\n",
    "        \n",
    "        # Check for departure time between 0 and 600 (0:00 to 6:00 AM)\n",
    "        # Times are usually in HHMM format (e.g., 1:30 AM = 130, 5:45 AM = 545)\n",
    "        redeye_departure = (df[dep_time_col] >= 0) & (df[dep_time_col] < 600)\n",
    "        df.loc[redeye_departure, 'IS_REDEYE'] = 1\n",
    "    \n",
    "    # If we have arrival time\n",
    "    if arr_time_cols:\n",
    "        arr_time_col = arr_time_cols[0]  # Use the first one found\n",
    "        \n",
    "        # Convert to float if it's not already\n",
    "        if df[arr_time_col].dtype != 'float64':\n",
    "            try:\n",
    "                df[arr_time_col] = df[arr_time_col].astype(float)\n",
    "            except:\n",
    "                # Handle any errors in conversion\n",
    "                print(f\"Warning: Could not convert {arr_time_col} to float\")\n",
    "        \n",
    "        # Check for arrival time between 0 and 600 (0:00 to 6:00 AM)\n",
    "        redeye_arrival = (df[arr_time_col] >= 0) & (df[arr_time_col] < 600)\n",
    "        df.loc[redeye_arrival, 'IS_REDEYE'] = 1\n",
    "    \n",
    "    # Print statistics about red-eye flights\n",
    "    redeye_count = df['IS_REDEYE'].sum()\n",
    "    total_count = len(df)\n",
    "    print(f\"Identified {redeye_count} red-eye flights out of {total_count} total flights ({redeye_count/total_count*100:.2f}%)\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T19:56:26.944704Z",
     "start_time": "2025-04-17T19:56:26.910729Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to train a Random Forest model for a single CSV file\n",
    "def train_model_for_file(file_path, file_index, total_files):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    model_name = os.path.splitext(file_name)[0]\n",
    "    file_year = extract_year_from_filename(file_name)  # Just for logging\n",
    "    \n",
    "    print(f\"\\nProcessing file {file_index+1}/{total_files}: {file_name} (May {file_year})\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load flight data from this file\n",
    "    try:\n",
    "        flight_df = pd.read_csv(file_path, low_memory=False)\n",
    "        original_size = len(flight_df)\n",
    "        \n",
    "        # Ensure we only have May data (in case the file contains other months)\n",
    "        if 'MONTH' in flight_df.columns:\n",
    "            month_counts = flight_df['MONTH'].value_counts()\n",
    "            print(f\"Months found in data: {dict(month_counts)}\")\n",
    "            \n",
    "            if 5 in month_counts:\n",
    "                flight_df = flight_df[flight_df['MONTH'] == 5]\n",
    "                print(f\"Filtered to only May data: {len(flight_df)} rows\")\n",
    "            else:\n",
    "                print(f\"Warning: No May data found in file, but proceeding anyway as this should be May data based on filename\")\n",
    "        \n",
    "        # Filter for top airports if we have the list\n",
    "        if top_airport_codes is not None:\n",
    "            flight_df = flight_df[\n",
    "                flight_df['ORIGIN_IATA'].str.strip().isin(top_airport_codes) & \n",
    "                flight_df['DEST_IATA'].str.strip().isin(top_airport_codes)\n",
    "            ]\n",
    "            \n",
    "            filtered_size = len(flight_df)\n",
    "            print(f\"Filtered from {original_size} to {filtered_size} rows for top 30 airports\")\n",
    "            \n",
    "            # If no data left after filtering, skip this file\n",
    "            if filtered_size == 0:\n",
    "                print(f\"No data remaining after filtering for top 30 airports. Skipping file.\")\n",
    "                return {\n",
    "                    'file_name': file_name,\n",
    "                    'status': 'skipped',\n",
    "                    'reason': 'empty_after_filtering'\n",
    "                }\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading flight data file {file_path}: {e}\")\n",
    "        return {\n",
    "            'file_name': file_name,\n",
    "            'status': 'error',\n",
    "            'reason': str(e)\n",
    "        }\n",
    "    \n",
    "    # Add red-eye flight indicator\n",
    "    print(\"Creating red-eye flight indicator...\")\n",
    "    flight_df = create_redeye_indicator(flight_df)\n",
    "    \n",
    "    # Basic information\n",
    "    print(f\"Final dataset shape: {flight_df.shape}\")\n",
    "    \n",
    "    # Data preprocessing\n",
    "    print(\"Preprocessing data...\")\n",
    "    \n",
    "    # Create target variable\n",
    "    if 'CANCELLED' in flight_df.columns:\n",
    "        flight_df['IS_CANCELLED'] = flight_df['CANCELLED'].astype(int)\n",
    "    else:\n",
    "        print(\"No CANCELLED column found. Skipping file.\")\n",
    "        return {\n",
    "            'file_name': file_name,\n",
    "            'status': 'skipped',\n",
    "            'reason': 'no_cancelled_column'\n",
    "        }\n",
    "    \n",
    "    # Ensure WEEK column exists\n",
    "    if 'WEEK' not in flight_df.columns:\n",
    "        if 'DAY_OF_WEEK' in flight_df.columns:\n",
    "            flight_df['WEEK'] = flight_df['DAY_OF_WEEK']\n",
    "        elif 'DAY' in flight_df.columns and 'MONTH' in flight_df.columns and 'YEAR' in flight_df.columns:\n",
    "            # Create DATE column if not exists\n",
    "            if 'DATE' not in flight_df.columns:\n",
    "                flight_df['DATE'] = pd.to_datetime(flight_df[['YEAR', 'MONTH', 'DAY']])\n",
    "            # Extract day of week (0=Monday, 6=Sunday)\n",
    "            flight_df['WEEK'] = flight_df['DATE'].dt.dayofweek\n",
    "        else:\n",
    "            print(\"Cannot create WEEK column. Required columns missing. Skipping file.\")\n",
    "            return {\n",
    "                'file_name': file_name,\n",
    "                'status': 'skipped',\n",
    "                'reason': 'missing_columns_for_week'\n",
    "            }\n",
    "    \n",
    "    # Analyze cancellation rates\n",
    "    cancelled_count = flight_df['IS_CANCELLED'].sum()\n",
    "    total_count = len(flight_df)\n",
    "    \n",
    "    # Skip if there are no cancellations (can't train a model)\n",
    "    if cancelled_count == 0:\n",
    "        print(f\"No cancelled flights in this dataset. Skipping file.\")\n",
    "        return {\n",
    "            'file_name': file_name,\n",
    "            'status': 'skipped',\n",
    "            'reason': 'no_cancelled_flights'\n",
    "        }\n",
    "    \n",
    "    cancellation_rate = cancelled_count / total_count * 100\n",
    "    print(f\"Overall cancellation rate: {cancelled_count}/{total_count} ({cancellation_rate:.2f}%)\")\n",
    "    \n",
    "    # Analyze cancellation rates by red-eye status\n",
    "    redeye_df = flight_df[flight_df['IS_REDEYE'] == 1]\n",
    "    non_redeye_df = flight_df[flight_df['IS_REDEYE'] == 0]\n",
    "    \n",
    "    if len(redeye_df) > 0:\n",
    "        redeye_cancel_rate = redeye_df['IS_CANCELLED'].mean() * 100\n",
    "        print(f\"Red-eye flights cancellation rate: {redeye_cancel_rate:.2f}%\")\n",
    "    \n",
    "    if len(non_redeye_df) > 0:\n",
    "        non_redeye_cancel_rate = non_redeye_df['IS_CANCELLED'].mean() * 100\n",
    "        print(f\"Non-red-eye flights cancellation rate: {non_redeye_cancel_rate:.2f}%\")\n",
    "    \n",
    "    # Match weather data with flights\n",
    "    print(\"Matching weather data with flights...\")\n",
    "    \n",
    "    # Create necessary keys and date columns\n",
    "    if 'YEAR' in flight_df.columns and 'MONTH' in flight_df.columns and 'DAY' in flight_df.columns:\n",
    "        flight_df['WEATHER_KEY'] = flight_df['ORIGIN_IATA'] + '_' + flight_df['YEAR'].astype(str) + '_' + flight_df['MONTH'].astype(str).str.zfill(2)\n",
    "        if 'FLIGHT_DATE' not in flight_df.columns:\n",
    "            flight_df['FLIGHT_DATE'] = pd.to_datetime(flight_df[['YEAR', 'MONTH', 'DAY']])\n",
    "    \n",
    "    # Create columns for extreme weather and precipitation\n",
    "    flight_df['EXTREME_WEATHER'] = 0  # Using exact name as specified\n",
    "    flight_df['PRCP'] = 0.0  # Using exact name as specified\n",
    "    \n",
    "    # Process in batches\n",
    "    matched_count = 0\n",
    "    batch_size = 5000  # Smaller batch size for individual files\n",
    "    \n",
    "    for start_idx in range(0, len(flight_df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(flight_df))\n",
    "        batch = flight_df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        for idx, row in batch.iterrows():\n",
    "            try:\n",
    "                weather_key = row['WEATHER_KEY']\n",
    "                flight_date = row['FLIGHT_DATE']\n",
    "                \n",
    "                if weather_key in weather_dict:\n",
    "                    weather_data = weather_dict[weather_key]\n",
    "                    # Convert to datetime if not already\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(weather_data['DATE']):\n",
    "                        weather_data['DATE'] = pd.to_datetime(weather_data['DATE'])\n",
    "                    \n",
    "                    # Find matching weather data for the flight date\n",
    "                    matching_weather = weather_data[weather_data['DATE'] == flight_date]\n",
    "                    \n",
    "                    if not matching_weather.empty:\n",
    "                        if 'EXTREME_WEATHER' in matching_weather.columns:\n",
    "                            flight_df.at[idx, 'EXTREME_WEATHER'] = matching_weather['EXTREME_WEATHER'].iloc[0]\n",
    "                        if 'PRCP' in matching_weather.columns:\n",
    "                            flight_df.at[idx, 'PRCP'] = matching_weather['PRCP'].iloc[0]\n",
    "                        matched_count += 1\n",
    "            except Exception as e:\n",
    "                # Less verbose error reporting for individual files\n",
    "                pass\n",
    "    \n",
    "    print(f\"Matched weather data for {matched_count} flights ({matched_count/len(flight_df)*100:.2f}%)\")\n",
    "    \n",
    "    # Feature selection - Using only the specified variables, now including IS_REDEYE but not YEAR\n",
    "    print(\"Selecting features...\")\n",
    "    \n",
    "    # Categorical features - Use specified ones but not YEAR\n",
    "    cat_features = [\"YEAR\", \"WEEK\", 'MKT_AIRLINE', 'ORIGIN_IATA', 'DEST_IATA', 'IS_REDEYE', 'IS_WEEKEND', 'IS_MORNING_PEAK', 'IS_EVENING_PEAK','EXTREME_WEATHER']\n",
    "    # Numerical features - Use specified ones plus IS_REDEYE\n",
    "    num_features = ['DISTANCE',  'PRCP']\n",
    "    \n",
    "    # Ensure all selected features exist in the dataframe\n",
    "    cat_features = [f for f in cat_features if f in flight_df.columns]\n",
    "    num_features = [f for f in num_features if f in flight_df.columns]\n",
    "    \n",
    "    if not cat_features or not num_features:\n",
    "        print(\"Missing required features. Skipping file.\")\n",
    "        return {\n",
    "            'file_name': file_name,\n",
    "            'status': 'skipped',\n",
    "            'reason': 'missing_required_features'\n",
    "        }\n",
    "    \n",
    "    print(f\"Using categorical features: {cat_features}\")\n",
    "    print(f\"Using numerical features: {num_features}\")\n",
    "    \n",
    "    # Create X (features) and y (target)\n",
    "    X = flight_df[cat_features + num_features].copy()\n",
    "    y = flight_df['IS_CANCELLED'].copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    for col in cat_features:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            X[col].fillna('unknown', inplace=True)\n",
    "    for col in num_features:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            X[col].fillna(X[col].median(), inplace=True)\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "    print(f\"Training set size: {X_train.shape}\")\n",
    "    print(f\"Test set size: {X_test.shape}\")\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Training Random Forest model...\")\n",
    "    model_start_time = time.time()\n",
    "    \n",
    "    # Define preprocessing steps\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_features),\n",
    "            ('cat', categorical_transformer, cat_features)\n",
    "        ])\n",
    "\n",
    "    # Create and train Random Forest model\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(\n",
    "            n_estimators=100,  # Number of trees in the forest\n",
    "            max_depth=10,      # Maximum depth of the trees\n",
    "            min_samples_split=10,  # Minimum samples required to split an internal node\n",
    "            min_samples_leaf=5,    # Minimum samples required at a leaf node\n",
    "            class_weight='balanced',  # Handle class imbalance\n",
    "            random_state=2025,     # For reproducibility\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    final_model = model\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    y_prob = final_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Feature importance from Random Forest\n",
    "    try:\n",
    "        # Get feature names from the preprocessor\n",
    "        feature_names = final_model.named_steps['preprocessor'].get_feature_names_out()\n",
    "        \n",
    "        # Get the trained Random Forest model\n",
    "        rf_model = final_model.named_steps['classifier']\n",
    "        \n",
    "        # Get feature importances from the model\n",
    "        importances = rf_model.feature_importances_\n",
    "        \n",
    "        # Create a DataFrame to store feature importances\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': importances\n",
    "        })\n",
    "        \n",
    "        # Sort by importance\n",
    "        feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting feature importances: {e}\")\n",
    "        feature_importance = pd.DataFrame()\n",
    "    \n",
    "    model_training_time = time.time() - model_start_time\n",
    "    print(f\"Model training took: {model_training_time:.2f} seconds\")\n",
    "    \n",
    "    # Evaluate model\n",
    "    print(\"Evaluating model...\")\n",
    "    \n",
    "    # Check if we have predictions for evaluation\n",
    "    if not isinstance(y_pred, np.ndarray) or len(y_pred) == 0:\n",
    "        print(\"No predictions available. Skipping evaluation.\")\n",
    "        return {\n",
    "            'file_name': file_name,\n",
    "            'status': 'error',\n",
    "            'reason': 'prediction_failed'\n",
    "        }\n",
    "    \n",
    "    # Calculate metrics\n",
    "    try:\n",
    "        accuracy = (y_pred == y_test).mean() * 100\n",
    "        roc_auc = roc_auc_score(y_test, y_prob)\n",
    "        \n",
    "        # Create classification report\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        # Create confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "        \n",
    "        # Feature importance analysis\n",
    "        if not feature_importance.empty:\n",
    "            # Print top features\n",
    "            print(\"\\nTop 10 most important features:\")\n",
    "            print(feature_importance.head(10))\n",
    "            \n",
    "            # Look specifically for IS_REDEYE importance\n",
    "            redeye_importance = feature_importance[feature_importance['Feature'] == 'IS_REDEYE']\n",
    "            if not redeye_importance.empty:\n",
    "                importance = redeye_importance.iloc[0]['Importance']\n",
    "                print(f\"\\nRed-eye flight importance: {importance:.6f}\")\n",
    "                print(f\"IS_REDEYE importance rank: {feature_importance[feature_importance['Feature'] == 'IS_REDEYE'].index[0] + 1} out of {len(feature_importance)}\")\n",
    "            \n",
    "            # Save feature importance to CSV\n",
    "            feature_importance.to_csv(os.path.join(output_dir, 'metrics', f\"{model_name}_feature_importance.csv\"), index=False)\n",
    "            \n",
    "            # Plot feature importance\n",
    "            plt.figure(figsize=(16, 10))\n",
    "            top_features = feature_importance.head(15)  # Top 15 features\n",
    "            sns.barplot(x='Importance', y='Feature', data=top_features)\n",
    "            plt.title(f'Top 15 Feature Importances for {model_name}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, 'plots', f\"{model_name}_feature_importance.png\"))\n",
    "            plt.close()\n",
    "        else:\n",
    "            print(\"Could not extract feature importances\")\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve for {model_name} (Random Forest)')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(output_dir, 'plots', f\"{model_name}_roc_curve.png\"))\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['Not Cancelled', 'Cancelled'],\n",
    "                   yticklabels=['Not Cancelled', 'Cancelled'])\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title(f'Confusion Matrix for {model_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'plots', f\"{model_name}_confusion_matrix.png\"))\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot cancellation rate comparison (red-eye vs non-red-eye)\n",
    "        if len(redeye_df) > 0 and len(non_redeye_df) > 0:\n",
    "            plt.figure(figsize=(16, 10))\n",
    "            categories = ['Non-Red-Eye', 'Red-Eye']\n",
    "            rates = [non_redeye_cancel_rate, redeye_cancel_rate]\n",
    "            counts = [len(non_redeye_df), len(redeye_df)]\n",
    "            \n",
    "            bars = plt.bar(categories, rates, color=['skyblue', 'navy'])\n",
    "            \n",
    "            # Add value labels on top of bars\n",
    "            for i, (bar, rate, count) in enumerate(zip(bars, rates, counts)):\n",
    "                plt.text(i, rate + 0.5, f\"{rate:.2f}%\\n({count} flights)\", \n",
    "                         ha='center', va='bottom')\n",
    "            \n",
    "            plt.ylabel('Cancellation Rate (%)')\n",
    "            plt.title(f'Cancellation Rate Comparison: Red-Eye vs. Non-Red-Eye Flights ({model_name})')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, 'plots', f\"{model_name}_redeye_comparison.png\"))\n",
    "            plt.close()\n",
    "        \n",
    "        # Generate partial dependence plot for IS_REDEYE feature\n",
    "        # This helps understand how the model's prediction changes with the red-eye flight status\n",
    "        try:\n",
    "            # Create feature-specific datasets\n",
    "            redeye_X_test = X_test.copy()\n",
    "            redeye_X_test['IS_REDEYE'] = 1\n",
    "            \n",
    "            non_redeye_X_test = X_test.copy()\n",
    "            non_redeye_X_test['IS_REDEYE'] = 0\n",
    "            \n",
    "            # Get predictions for both scenarios\n",
    "            redeye_probs = final_model.predict_proba(redeye_X_test)[:, 1]\n",
    "            non_redeye_probs = final_model.predict_proba(non_redeye_X_test)[:, 1]\n",
    "            \n",
    "            # Calculate the average effect\n",
    "            avg_redeye_effect = np.mean(redeye_probs - non_redeye_probs)\n",
    "            \n",
    "            # Plot distribution of effects\n",
    "            plt.figure(figsize=(16, 10))\n",
    "            \n",
    "            # Plot the differences for each sample\n",
    "            differences = redeye_probs - non_redeye_probs\n",
    "            sns.histplot(differences, bins=30, kde=True)\n",
    "            \n",
    "            plt.axvline(avg_redeye_effect, color='red', linestyle='--', \n",
    "                       label=f'Average effect: {avg_redeye_effect:.4f}')\n",
    "            plt.xlabel('Change in Cancellation Probability (Red-Eye - Non-Red-Eye)')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.title(f'Red-Eye Flight Effect on Cancellation Probability ({model_name})')\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, 'plots', f\"{model_name}_redeye_effect.png\"))\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"Average effect of being a red-eye flight on cancellation probability: {avg_redeye_effect:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating red-eye effect plot: {e}\")\n",
    "        \n",
    "        # Save model\n",
    "        model_path = os.path.join(output_dir, f\"{model_name}_model.joblib\")\n",
    "        dump(final_model, model_path)\n",
    "        print(f\"Model saved to {model_path}\")\n",
    "        \n",
    "        # Save metrics summary\n",
    "        metrics = {\n",
    "            'file_name': file_name,\n",
    "            'model_name': model_name,\n",
    "            'file_year': file_year,  # Just for reference, not used as a feature\n",
    "            'accuracy': accuracy,\n",
    "            'roc_auc': roc_auc,\n",
    "            'precision': report['1']['precision'],\n",
    "            'recall': report['1']['recall'],\n",
    "            'f1_score': report['1']['f1-score'],\n",
    "            'cancellation_rate': cancellation_rate,\n",
    "            'training_time': model_training_time,\n",
    "            'training_size': len(X_train),\n",
    "            'test_size': len(X_test),\n",
    "            'status': 'success'\n",
    "        }\n",
    "        \n",
    "        # Add red-eye specific metrics\n",
    "        metrics['redeye_count'] = len(redeye_df)\n",
    "        metrics['redeye_percentage'] = len(redeye_df) / len(flight_df) * 100\n",
    "        metrics['redeye_cancel_rate'] = redeye_cancel_rate if len(redeye_df) > 0 else None\n",
    "        metrics['non_redeye_cancel_rate'] = non_redeye_cancel_rate if len(non_redeye_df) > 0 else None\n",
    "        \n",
    "        # If IS_REDEYE feature importance available, add it\n",
    "        if not redeye_importance.empty:\n",
    "            metrics['redeye_importance'] = importance\n",
    "            metrics['redeye_rank'] = feature_importance[feature_importance['Feature'] == 'IS_REDEYE'].index[0] + 1\n",
    "        \n",
    "        # Add red-eye effect from partial dependence if available\n",
    "        if 'avg_redeye_effect' in locals():\n",
    "            metrics['redeye_effect'] = avg_redeye_effect\n",
    "        \n",
    "        # Save confusion matrix values\n",
    "        metrics['true_negative'] = cm[0, 0]\n",
    "        metrics['false_positive'] = cm[0, 1]\n",
    "        metrics['false_negative'] = cm[1, 0]\n",
    "        metrics['true_positive'] = cm[1, 1]\n",
    "        \n",
    "        # Save top 5 most important features\n",
    "        if not feature_importance.empty:\n",
    "            for i in range(min(5, len(feature_importance))):\n",
    "                feat = feature_importance.iloc[i]\n",
    "                metrics[f'top_feature_{i+1}'] = feat['Feature']\n",
    "                metrics[f'top_feature_{i+1}_importance'] = feat['Importance']\n",
    "        \n",
    "        print(f\"Processing of {file_name} completed in {time.time() - start_time:.2f} seconds\")\n",
    "        return metrics\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in evaluation: {e}\")\n",
    "        return {\n",
    "            'file_name': file_name,\n",
    "            'status': 'error',\n",
    "            'reason': str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T19:57:11.550220Z",
     "start_time": "2025-04-17T19:56:26.963806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file 1/4: May2021.csv (May 2021)\n",
      "Months found in data: {5: 520059}\n",
      "Filtered to only May data: 520059 rows\n",
      "Filtered from 520059 to 171867 rows for top 30 airports\n",
      "Creating red-eye flight indicator...\n",
      "Identified 7202 red-eye flights out of 171867 total flights (4.19%)\n",
      "Final dataset shape: (171867, 52)\n",
      "Preprocessing data...\n",
      "Overall cancellation rate: 485/171867 (0.28%)\n",
      "Red-eye flights cancellation rate: 0.22%\n",
      "Non-red-eye flights cancellation rate: 0.28%\n",
      "Matching weather data with flights...\n",
      "Matched weather data for 0 flights (0.00%)\n",
      "Selecting features...\n",
      "Using categorical features: ['YEAR', 'WEEK', 'MKT_AIRLINE', 'ORIGIN_IATA', 'DEST_IATA', 'IS_REDEYE', 'EXTREME_WEATHER']\n",
      "Using numerical features: ['DISTANCE', 'PRCP']\n",
      "Training set size: (154680, 9)\n",
      "Test set size: (17187, 9)\n",
      "Training Random Forest model...\n",
      "Model training took: 1.93 seconds\n",
      "Evaluating model...\n",
      "Accuracy: 92.23%\n",
      "ROC AUC: 0.8659\n",
      "\n",
      "Top 10 most important features:\n",
      "                 Feature  Importance\n",
      "13   cat__MKT_AIRLINE_DL    0.141984\n",
      "10   cat__MKT_AIRLINE_AA    0.139201\n",
      "27  cat__ORIGIN_IATA_DFW    0.100250\n",
      "57    cat__DEST_IATA_DFW    0.088545\n",
      "8          cat__WEEK_Tue    0.076231\n",
      "0          num__DISTANCE    0.074498\n",
      "3          cat__WEEK_Fri    0.031739\n",
      "5          cat__WEEK_Sat    0.029020\n",
      "7          cat__WEEK_Thu    0.024816\n",
      "4          cat__WEEK_Mon    0.023822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_7712\\2899471482.py:369: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average effect of being a red-eye flight on cancellation probability: -0.0107\n",
      "Model saved to ./cancelled_prob_rf_models/May2021_model.joblib\n",
      "Processing of May2021.csv completed in 9.39 seconds\n",
      "\n",
      "Processing file 2/4: May2022.csv (May 2022)\n",
      "Months found in data: {5: 602950}\n",
      "Filtered to only May data: 602950 rows\n",
      "Filtered from 602950 to 210079 rows for top 30 airports\n",
      "Creating red-eye flight indicator...\n",
      "Identified 13296 red-eye flights out of 210079 total flights (6.33%)\n",
      "Final dataset shape: (210079, 51)\n",
      "Preprocessing data...\n",
      "Overall cancellation rate: 4659/210079 (2.22%)\n",
      "Red-eye flights cancellation rate: 1.56%\n",
      "Non-red-eye flights cancellation rate: 2.26%\n",
      "Matching weather data with flights...\n",
      "Matched weather data for 0 flights (0.00%)\n",
      "Selecting features...\n",
      "Using categorical features: ['YEAR', 'WEEK', 'MKT_AIRLINE', 'ORIGIN_IATA', 'DEST_IATA', 'IS_REDEYE', 'EXTREME_WEATHER']\n",
      "Using numerical features: ['DISTANCE', 'PRCP']\n",
      "Training set size: (189071, 9)\n",
      "Test set size: (21008, 9)\n",
      "Training Random Forest model...\n",
      "Model training took: 2.96 seconds\n",
      "Evaluating model...\n",
      "Accuracy: 70.83%\n",
      "ROC AUC: 0.7889\n",
      "\n",
      "Top 10 most important features:\n",
      "                 Feature  Importance\n",
      "9          cat__WEEK_Wed    0.138073\n",
      "3          cat__WEEK_Fri    0.094299\n",
      "7          cat__WEEK_Thu    0.087358\n",
      "0          num__DISTANCE    0.073734\n",
      "18   cat__MKT_AIRLINE_WN    0.069228\n",
      "8          cat__WEEK_Tue    0.062125\n",
      "13   cat__MKT_AIRLINE_DL    0.055870\n",
      "59    cat__DEST_IATA_EWR    0.038308\n",
      "66    cat__DEST_IATA_LGA    0.030178\n",
      "36  cat__ORIGIN_IATA_LGA    0.029026\n",
      "Average effect of being a red-eye flight on cancellation probability: -0.0169\n",
      "Model saved to ./cancelled_prob_rf_models/May2022_model.joblib\n",
      "Processing of May2022.csv completed in 11.31 seconds\n",
      "\n",
      "Processing file 3/4: May2023.csv (May 2023)\n",
      "Months found in data: {5: 616630}\n",
      "Filtered to only May data: 616630 rows\n",
      "Filtered from 616630 to 220469 rows for top 30 airports\n",
      "Creating red-eye flight indicator...\n",
      "Identified 15208 red-eye flights out of 220469 total flights (6.90%)\n",
      "Final dataset shape: (220469, 51)\n",
      "Preprocessing data...\n",
      "Overall cancellation rate: 1293/220469 (0.59%)\n",
      "Red-eye flights cancellation rate: 0.74%\n",
      "Non-red-eye flights cancellation rate: 0.57%\n",
      "Matching weather data with flights...\n",
      "Matched weather data for 0 flights (0.00%)\n",
      "Selecting features...\n",
      "Using categorical features: ['YEAR', 'WEEK', 'MKT_AIRLINE', 'ORIGIN_IATA', 'DEST_IATA', 'IS_REDEYE', 'EXTREME_WEATHER']\n",
      "Using numerical features: ['DISTANCE', 'PRCP']\n",
      "Training set size: (198422, 9)\n",
      "Test set size: (22047, 9)\n",
      "Training Random Forest model...\n",
      "Model training took: 2.93 seconds\n",
      "Evaluating model...\n",
      "Accuracy: 79.44%\n",
      "ROC AUC: 0.7085\n",
      "\n",
      "Top 10 most important features:\n",
      "                 Feature  Importance\n",
      "0          num__DISTANCE    0.102604\n",
      "8          cat__WEEK_Tue    0.068738\n",
      "3          cat__WEEK_Fri    0.056263\n",
      "7          cat__WEEK_Thu    0.051024\n",
      "10   cat__MKT_AIRLINE_AA    0.046980\n",
      "62    cat__DEST_IATA_IAH    0.038654\n",
      "32  cat__ORIGIN_IATA_IAH    0.038147\n",
      "6          cat__WEEK_Sun    0.036054\n",
      "17   cat__MKT_AIRLINE_UA    0.035871\n",
      "13   cat__MKT_AIRLINE_DL    0.035051\n",
      "Average effect of being a red-eye flight on cancellation probability: 0.0054\n",
      "Model saved to ./cancelled_prob_rf_models/May2023_model.joblib\n",
      "Processing of May2023.csv completed in 11.44 seconds\n",
      "\n",
      "Processing file 4/4: May2024.csv (May 2024)\n",
      "Months found in data: {5: 649428}\n",
      "Filtered to only May data: 649428 rows\n",
      "Filtered from 649428 to 228159 rows for top 30 airports\n",
      "Creating red-eye flight indicator...\n",
      "Identified 14238 red-eye flights out of 228159 total flights (6.24%)\n",
      "Final dataset shape: (228159, 51)\n",
      "Preprocessing data...\n",
      "Overall cancellation rate: 2994/228159 (1.31%)\n",
      "Red-eye flights cancellation rate: 1.76%\n",
      "Non-red-eye flights cancellation rate: 1.28%\n",
      "Matching weather data with flights...\n",
      "Matched weather data for 0 flights (0.00%)\n",
      "Selecting features...\n",
      "Using categorical features: ['YEAR', 'WEEK', 'MKT_AIRLINE', 'ORIGIN_IATA', 'DEST_IATA', 'IS_REDEYE', 'EXTREME_WEATHER']\n",
      "Using numerical features: ['DISTANCE', 'PRCP']\n",
      "Training set size: (205343, 9)\n",
      "Test set size: (22816, 9)\n",
      "Training Random Forest model...\n",
      "Model training took: 3.31 seconds\n",
      "Evaluating model...\n",
      "Accuracy: 76.03%\n",
      "ROC AUC: 0.8084\n",
      "\n",
      "Top 10 most important features:\n",
      "                 Feature  Importance\n",
      "13   cat__MKT_AIRLINE_DL    0.161487\n",
      "10   cat__MKT_AIRLINE_AA    0.124548\n",
      "57    cat__DEST_IATA_DFW    0.096943\n",
      "27  cat__ORIGIN_IATA_DFW    0.091685\n",
      "0          num__DISTANCE    0.085882\n",
      "18   cat__MKT_AIRLINE_WN    0.056370\n",
      "7          cat__WEEK_Thu    0.028351\n",
      "5          cat__WEEK_Sat    0.027254\n",
      "14   cat__MKT_AIRLINE_F9    0.027183\n",
      "62    cat__DEST_IATA_IAH    0.026027\n",
      "Average effect of being a red-eye flight on cancellation probability: 0.0048\n",
      "Model saved to ./cancelled_prob_rf_models/May2024_model.joblib\n",
      "Processing of May2024.csv completed in 12.25 seconds\n",
      "\n",
      "Summary of Random Forest model training:\n",
      "Successfully trained models: 4/4\n",
      "Failed models: 0/4\n",
      "Skipped files: 0/4\n",
      "\n",
      "Average metrics across all successful models:\n",
      "Accuracy: 79.63%\n",
      "ROC AUC: 0.7929\n",
      "Precision: 0.0326\n",
      "Recall: 0.6559\n",
      "\n",
      "Most common important features across all models:\n",
      "cat__MKT_AIRLINE_AA: Appears in 3 models (75.0%)\n",
      "num__DISTANCE: Appears in 3 models (75.0%)\n",
      "cat__MKT_AIRLINE_DL: Appears in 2 models (50.0%)\n",
      "cat__ORIGIN_IATA_DFW: Appears in 2 models (50.0%)\n",
      "cat__DEST_IATA_DFW: Appears in 2 models (50.0%)\n",
      "cat__WEEK_Tue: Appears in 2 models (50.0%)\n",
      "cat__WEEK_Fri: Appears in 2 models (50.0%)\n",
      "cat__WEEK_Thu: Appears in 2 models (50.0%)\n",
      "cat__WEEK_Wed: Appears in 1 models (25.0%)\n",
      "cat__MKT_AIRLINE_WN: Appears in 1 models (25.0%)\n",
      "\n",
      "Average red-eye vs non-red-eye cancellation rate comparison saved to average_redeye_comparison.png\n",
      "\n",
      "Random Forest model training with red-eye flight detection complete!\n",
      "Full summary saved to ./cancelled_prob_rf_models/cancelled_prob_rf_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Sequential processing of the May files\n",
    "results = []\n",
    "for i, file_path in enumerate(flight_files):\n",
    "    result = train_model_for_file(file_path, i, len(flight_files))\n",
    "    results.append(result)\n",
    "\n",
    "# Summarize results\n",
    "print(\"\\nSummary of Random Forest model training:\")\n",
    "success_count = sum(1 for r in results if r.get('status') == 'success')\n",
    "error_count = sum(1 for r in results if r.get('status') == 'error')\n",
    "skipped_count = sum(1 for r in results if r.get('status') == 'skipped')\n",
    "\n",
    "print(f\"Successfully trained models: {success_count}/{len(results)}\")\n",
    "print(f\"Failed models: {error_count}/{len(results)}\")\n",
    "print(f\"Skipped files: {skipped_count}/{len(results)}\")\n",
    "\n",
    "# Create a summary DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(os.path.join(output_dir, 'cancelled_prob_rf_summary.csv'), index=False)\n",
    "\n",
    "# Calculate average metrics for successful models\n",
    "if success_count > 0:\n",
    "    successful_results = [r for r in results if r.get('status') == 'success']\n",
    "    avg_accuracy = sum(r.get('accuracy', 0) for r in successful_results) / success_count\n",
    "    avg_roc_auc = sum(r.get('roc_auc', 0) for r in successful_results) / success_count\n",
    "    avg_precision = sum(r.get('precision', 0) for r in successful_results) / success_count\n",
    "    avg_recall = sum(r.get('recall', 0) for r in successful_results) / success_count\n",
    "    \n",
    "    print(\"\\nAverage metrics across all successful models:\")\n",
    "    print(f\"Accuracy: {avg_accuracy:.2f}%\")\n",
    "    print(f\"ROC AUC: {avg_roc_auc:.4f}\")\n",
    "    print(f\"Precision: {avg_precision:.4f}\")\n",
    "    print(f\"Recall: {avg_recall:.4f}\")\n",
    "    \n",
    "    # For successful models, identify most common important features\n",
    "    feature_counts = {}\n",
    "    for result in successful_results:\n",
    "        for i in range(1, 6):  # Top 5 features\n",
    "            feature_key = f'top_feature_{i}'\n",
    "            if feature_key in result:\n",
    "                feature = result[feature_key]\n",
    "                if feature in feature_counts:\n",
    "                    feature_counts[feature] += 1\n",
    "                else:\n",
    "                    feature_counts[feature] = 1\n",
    "    \n",
    "    if feature_counts:\n",
    "        print(\"\\nMost common important features across all models:\")\n",
    "        sorted_features = sorted(feature_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        for feature, count in sorted_features[:10]:  # Top 10 most common\n",
    "            print(f\"{feature}: Appears in {count} models ({count/success_count*100:.1f}%)\")\n",
    "    \n",
    "    # Analyze red-eye flight effects across all models\n",
    "    if all('redeye_importance' in r for r in successful_results):\n",
    "        importances = [r['redeye_importance'] for r in successful_results]\n",
    "        avg_importance = sum(importances) / len(importances)\n",
    "        \n",
    "        print(f\"\\nRed-eye flight importance (across all models):\")\n",
    "        print(f\"Average IS_REDEYE importance: {avg_importance:.6f}\")\n",
    "        \n",
    "        # Check red-eye effect from partial dependence if available\n",
    "        if all('redeye_effect' in r for r in successful_results):\n",
    "            effects = [r['redeye_effect'] for r in successful_results]\n",
    "            avg_effect = sum(effects) / len(effects)\n",
    "            \n",
    "            effect_dir = \"increases\" if avg_effect > 0 else \"decreases\"\n",
    "            print(f\"Being a red-eye flight generally {effect_dir} cancellation probability by {abs(avg_effect):.4f}\")\n",
    "    \n",
    "    # Plot combined red-eye vs non-red-eye cancellation rate comparison\n",
    "    if all('redeye_cancel_rate' in r and 'non_redeye_cancel_rate' in r for r in successful_results):\n",
    "        redeye_rates = [r['redeye_cancel_rate'] for r in successful_results if r['redeye_cancel_rate'] is not None]\n",
    "        non_redeye_rates = [r['non_redeye_cancel_rate'] for r in successful_results if r['non_redeye_cancel_rate'] is not None]\n",
    "        \n",
    "        if redeye_rates and non_redeye_rates:\n",
    "            avg_redeye_rate = sum(redeye_rates) / len(redeye_rates)\n",
    "            avg_non_redeye_rate = sum(non_redeye_rates) / len(non_redeye_rates)\n",
    "            \n",
    "            # Total counts across all models\n",
    "            redeye_counts = [r.get('redeye_count', 0) for r in successful_results]\n",
    "            total_redeye = sum(redeye_counts)\n",
    "            total_non_redeye = sum(r.get('training_size', 0) + r.get('test_size', 0) for r in successful_results) - total_redeye\n",
    "            \n",
    "            plt.figure(figsize=(16, 10))\n",
    "            categories = ['Non-Red-Eye', 'Red-Eye']\n",
    "            rates = [avg_non_redeye_rate, avg_redeye_rate]\n",
    "            \n",
    "            bars = plt.bar(categories, rates, color=['skyblue', 'navy'])\n",
    "            \n",
    "            # Add value labels\n",
    "            for i, (bar, rate, count) in enumerate(zip(bars, rates, [total_non_redeye, total_redeye])):\n",
    "                plt.text(i, rate + 0.5, f\"{rate:.2f}%\\n({count} flights)\", \n",
    "                         ha='center', va='bottom')\n",
    "            \n",
    "            plt.ylabel('Average Cancellation Rate (%)')\n",
    "            plt.title('Average Cancellation Rate Comparison: Red-Eye vs. Non-Red-Eye Flights')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, 'plots', 'average_redeye_comparison.png'))\n",
    "            plt.close()\n",
    "            print(\"\\nAverage red-eye vs non-red-eye cancellation rate comparison saved to average_redeye_comparison.png\")\n",
    "\n",
    "print(\"\\nRandom Forest model training with red-eye flight detection complete!\")\n",
    "print(f\"Full summary saved to {os.path.join(output_dir, 'cancelled_prob_rf_summary.csv')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
